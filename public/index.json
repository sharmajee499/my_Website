[{"authors":null,"categories":null,"content":"Couples of year ago, I saw the immense capability of analytics. So, I decided to make people see the power of data in decision making which could be applied to any domain.\nPersonally, I am interested in solving business and organizational problem through the data-driven approaches. Pointing out as well as excluding biases on algorithmic decision making to promote ethics has always been my core value.\n#NoRoomForAnyDiscrimination ","date":1639094400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1639094400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://sharmajee499.netlify.app/author/sandesh-sharma/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sandesh-sharma/","section":"authors","summary":"Couples of year ago, I saw the immense capability of analytics. So, I decided to make people see the power of data in decision making which could be applied to any domain.","tags":null,"title":"Sandesh Sharma","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bb560906b6a99893cc21387348c0b074","permalink":"https://sharmajee499.netlify.app/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"","tags":null,"title":"Âê≥ÊÅ©ÈÅî","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  What you will learn Program overview Courses in this program Meet your instructor FAQs    What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program  Python basics Build a foundation in Python.   Visualization Learn how to visualize data with Plotly.   Statistics Introduction to statistics for data science.   Meet your instructor Sandesh Sharma FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://sharmajee499.netlify.app/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"üìä Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz What is the difference between lists and tuples? Lists\n Lists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, 'Hello world']  Tuples\n Tuples are immutable - they can\u0026rsquo;t be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, 'Hello world')   Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"https://sharmajee499.netlify.app/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n Write Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026quot;country == 'Canada'\u0026quot;) fig = px.bar(data_canada, x='year', y='pop') fig.show()  ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"https://sharmajee499.netlify.app/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n  1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n The parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$.   Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"https://sharmajee499.netlify.app/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":null,"categories":null,"content":"\rIntroduction\rGradient Boosting (GB) is one of the most popular algorithms in the\rMachine Learning/Data Science community. You might heard about various\rversion of boosting algorithms like Ada-boost, XG Boost, LG Boost,\rCatBoost. They are very famous for wining the Kaggle competition. In\rthis article, I want to talk about the vanilla Gradient Boosting and\rit‚Äôs working principle with some mathematical background.\nThe fundamental working principle of the boosting algorithms is to\rcombine a number of weak learner into a stronger ensemble. The boosting\ralgorithms sequential trains the weak learners and repeat the process.\nLet us straight dive into the algorithm and it‚Äôs working principle then\rit will make more sense to you. Below picture is captured from the\rWikipedia article\rwhich shows the pseudo algorithm. You can also find the in-depth\rdescription on the original paper by Friedman\r(2001).\n\rAlgorithm Breakdown\rStep 1:\rLet‚Äôs look at the step one of the algorithm.\nInitialize model with a constant value:\r\r\\[F_0(x) = \\underset{\\gamma}{\\operatorname{argmin}} \\sum_{i=1}^{n}L(y_i, \\gamma)\\]\rIn the first step we need to find the constant value to initialize our\rbase learner/first weak learner. From the equation, we see that we need\rto find \\(\\gamma\\) such that it minimized our loss function. Now, we need\ra loss function. Let‚Äôs assume we are working on the regression problem\rand we choose are loss function to be squared error(SE). Keep in mind,\ryou can choose another loss function also. The formula for SE is:\n\\[SE = (y_i - \\hat{y_i})^2\\]\nHere, we will replace \\(\\hat{y_i}\\) with our \\(\\gamma\\) and the function\rbecomes: \\[L_{SE} = (y_i - \\gamma)^2\\]\nThe question arises how we will find the value that minimized the loss\rfunction. Here, comes our old friend derivative. We will take derivative\rof the loss function with respect to \\(\\gamma\\) and then equalize to zero\rto find the minimum value. The above SE equation only showed error for a\robservation. We have to sum the error of whole data to get total error.\rTherefore, the equation changes to:\n\\[\\frac{\\partial}{\\partial {\\gamma}} (\\sum_{i=1}^n(y_i - \\gamma)^2)\\]\nLet‚Äôs apply chain rule and we will get:\n\\[2 \\sum_1^n (y_i -\\gamma) \\left(\\frac{\\partial(y_i - \\gamma)}{\\partial{\\gamma}}\\right)\\]\r\\[2 \\sum_1^n (y_i -\\gamma) \\left(\\frac{\\partial{y_i}}{\\partial{\\gamma}} - \\frac{\\partial{\\gamma}}{\\partial{\\gamma}}\\right)\\]\r\\[2 \\sum_1^n (y_i -\\gamma) (-1)\\]\nNow, to find the value of \\(\\gamma\\) that minimized the function, we will\requalize above equation with zero.\n\\[\\Rightarrow -2 \\sum_{i=1}^n(y_i-\\gamma) = 0\\]\r\\[\\Rightarrow \\sum_{i=1}^ny_i - n\\gamma = 0\\]\r\\[\\gamma = \\frac{\\sum_{i=1}^ny_i}{n} \\tag{1}\\]\nIf you look at the \\(Eq1\\), you will see that \\(\\gamma\\) is equal to the\rmean of the target value(considering this as a regression problem).\rTherefore, the predicted value of our first weak model is the mean of\rthe dependent variable. Meaning, if we choose mean to be our base\rlearners predicted value then it will minimize the loss.\n\rStep 2:\rIn the step 2, we iterate the below process for \\(M\\) times. Here, \\(M\\)\rrepresents the number of trees one wants in their GB algorithm.\nStep 2.1\rIn step 2.1, we are calculating the residual. We compute the\rpseudo-residual by taking the derivative of the loss function with\rrespect to our previous prediction. Let‚Äôs look at the equation and\rmathematically derivative the equation:\n\\[r_{im} = -\\left[ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)} \\right]_{F(x) = F_{m-1}(x)} \\text{for i=1,...,n} \\tag{2}\\]\nThe derivative of the \\(Eq2\\) is similar to the above loss function\rderivative. If you replace \\(F(x_i)\\) with \\(\\gamma\\) both of the equation\rare identical. Therefore, the result are same which is:\n\\[= -1*-2(y_i - F_{m-1})\\] \\[ = 2(y_i - F_{m-1}) \\tag{3}\\]\nIf you remove 2, which is a constant, then you will see that why it is\rcalled pseudo-residual.\n\rStep 2.2\rIn this step, we will fit the base learner, Decision Tree, making the\rpseudo-residual dependent variable\n\rStep 2.3\rIn step 3 we calculate the multiplier \\(\\gamma_m\\) which is needed to\rupdate our model in next step. This is done by finding the minimum value\rof below function. Here, we are trying to minimize the loss function on\reach terminal node of our Decision Tree- \\(h_m(x_i)\\)\n\\[\\gamma_m = \\underset{\\gamma}{\\operatorname{argmin}} \\sum_{i=1}^n L(y_i, F_{m-1}(x_i) + \\gamma h_m(x_i)) \\tag{4}\\]\nThe \\(Eq4\\) is similar to our equation in Step 1. The only difference is,\rhere we also have to consider the output of our previous learners\rprediction which is \\(F_{m-1}(x_i)\\)\n\rStep 2.4\rWe will slightly change this step. The above formula is the official\rgeneralization of the GB algorithm from the original paper. However,\rthat is more prone to over-fitting. Therefore, we will use shrinkage\rmethod as a regularization to make model robust. Therefore, the equation\rbecomes:\n\\[F_m(x) = F_{m-1}(x) + \\nu . \\gamma_m h_m(x), 0\u0026lt;\\nu \\le 1 \\tag{5}\\]\nwhere \\(\\nu\\) is learning rate that we have to pre-define. The \\(Eq5\\) is\rsimply adding the output of the previous model with learning rate\rmultiplied by currently predicted value by the decision tree. If the\riteration was first, then the \\(F_{m-1}(x)\\) would be the mean and\r\\(\\gamma_m h_m(x)\\) would be the predicted value of the first decision\rtree.\n\r\r\rPython Implementation\r\r# Import Libraries and Data\rfrom sklearn.datasets import load_diabetes\rfrom sklearn.tree import DecisionTreeRegressor\rfrom sklearn import metrics\rimport numpy as np\rfrom sklearn.ensemble import GradientBoostingRegressor\r# data and split\rdf= load_diabetes()\rtrain_size = 300\rx_train, y_train = df.data[:train_size], df.target[:train_size]\rx_test, y_test = df.data[train_size:], df.target[train_size:]\rnp.random.seed(112233)\r\r# Create the Pre-requisite for the Gradient Boost\r# Number of Decision Tree\rdt_size = 50\r# Learning Rate\rlr = 0.1\r# Placeholder for all base learners\rbase_learner = []\r# Initial Prediction (which is mean: Step 1)\rprv_pred = np.zeros(len(y_train))+ np.mean(y_train)\r\r# Loop (Step 2)\rfor i in range(dt_size):\r# Pseudo Residuals\rerr = y_train - prv_pred\r# Train decision tree on the pseudo residual dt = DecisionTreeRegressor(max_depth=1, random_state=112233)\rdt.fit(x_train, err)\r# Prediction of the decision tree\rgamma = dt.predict(x_train)\r# Update the model\rprv_pred = prv_pred + lr * gamma\r# Save the base learners\rbase_learner.append(dt);\r\r# Make the prediction\r# Again initializing the base learner prediction which is mean for test data prediction\rpred0 = np.zeros(len(y_test))+ np.mean(y_test)\r# Loop through the learners to predict\rfor learner in base_learner:\rprediction = learner.predict(x_test)\rpred0 = pred0 + (lr * prediction);\r\r# Evaluations using RMSE\rrmse = metrics.mean_squared_error(y_test, pred0, squared=False)\rprint(f\u0026quot;RMSE: {rmse}\u0026quot;)\r## RMSE: 56.54069228996236\r\r# Now Using the Sklearn Package for comparison\rgbr = GradientBoostingRegressor(n_estimators=dt_size, max_depth=1, learning_rate=lr, random_state=112233)\rgbr.fit(x_train, y_train)\r## GradientBoostingRegressor(max_depth=1, n_estimators=50, random_state=112233)\rgbr_pred = gbr.predict(x_test)\rgbr_err = metrics.mean_squared_error(y_test, gbr_pred, squared=False)\rprint(f\u0026quot;RMSE: {rmse}\u0026quot;)\r## RMSE: 56.54069228996236\rprint(f\u0026quot;RMSE (sklearn) : {gbr_err}\u0026quot;)\r## RMSE (sklearn) : 56.19156351809499\rFrom the above result, you can see that we got the similar RMSE from\rscratch model as well as model from the sklearn package. I would highly\rrecommend to watch the video by Josh Starmer to better understand the\rmodel. Here is the link\n\rReferences\rFriedman, J. H. (2001). Greedy function approximation: a gradient\rboosting machine. Annals of statistics, 1189-1232.\r\r\r","date":1670889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670889600,"objectID":"3105cc0ea0146a182c2a593d38d85ca7","permalink":"https://sharmajee499.netlify.app/post/gradient_-boosting/","publishdate":"2022-12-13T00:00:00Z","relpermalink":"/post/gradient_-boosting/","section":"post","summary":"Introduction\rGradient Boosting (GB) is one of the most popular algorithms in the\rMachine Learning/Data Science community. You might heard about various\rversion of boosting algorithms like Ada-boost, XG Boost, LG Boost,\rCatBoost.","tags":null,"title":"Gradient Boosting: Principles \u0026 Implementation","type":"post"},{"authors":null,"categories":null,"content":"\rStationarity is one of the major concept that needed to be understood in\rorder to model any time series. The\rWikipedia\rdefines stationary process as ‚Äúa stochastic process whose unconditional\rjoint probability distribution does not change when shifted in time.‚Äù.\rThis simply means the given time series will have constant mean,\rvariance and auto-correlation which are independent of time. Various\rforecasting models assumes the data to be stationary. Below I am quoting\rthe words from the Time Series Forecasting In\rPython\rwhich clearly says why stationarity matters for forecasting.\n\r‚ÄúThese models can only be used if we verify that the data is indeed\rstationary. Otherwise, the models will not be valid, and the forecasts\rwill not be reliable. Intuitively, this makes sense, because if the\rdata is non-stationary, its properties are going change over time, and\rso it would mean that our model parameters must also change through\rtime. This means that we cannot possibly derive a function of future\rvalues as a function of past values, since the coefficients change at\reach point in time, hence making forecasting unreliable.‚Äù\n\rTherefore, before modeling any forecast model we need to check the\rstationarity of the time series data.\nAugmented Dickey-Fuller Test (ADF Test)\rADF is an one of the common method to test the stationarity of the data.\rADF is similar to the Dickey-Fuller Test. The only difference between\rthe ADF and Dickey-Fuller Test is that Dickey-Fuller Test is used for\rAR(1) (Autoregressive model with order 1) model whereas ADF is augmented\rversion used to generalize AR(p) models. You can refer to\rthis\rwebsite for more details.\nIn this article, we will derive the Dickey-Fuller test and expand the\rsame concept to understand ADF.\nWe have a univariate time-series data of \\(y\\) then, the Autoregressive\rmodel of order 1 (AR 1) can be written in :\r\\[\\text{AR (1) ‚Üí } y_{t} = \\alpha + \\phi_{1}y_{t-1} + \\epsilon_{t} \\tag{1}\\]\rHere, \\(\\alpha\\) is a constant, \\(\\epsilon_{t}\\) is a white noise and\r\\(\\phi_1\\) is a coefficient. You might find this equation resembling to\rthe simple linear regression equation. For now, you can think like that.\nNow, our hypothesis are: \\[H_0 : \\phi_1=1\\]\\[H_1 : \\phi_1 \u0026lt; 1\\] If\r\\(\\phi_1\\) equals to one then, we have a unit root. That means we have a\rrandom walk, which is not stationary. However, if \\(\\phi_1\\) \u0026lt; 1 means\rthe process is stationary. In a random walk, the present \\(y_t\\) is a\rfunction of previous time stamp \\(y_{t-1}\\), a constant \\(\\alpha\\), and\rrandom number \\(\\epsilon_t\\) also known as white noise.\nNow, we will change the \\(Equation1\\) to find out our test statistics.\nFirst, we will subtract \\(y_{t-1}\\) from both sides\n\\[y_t - y_{t-1} = \\alpha+ \\phi_1 y_{t-1} + \\epsilon_t - y_{t-1} \\] Let‚Äôs\rassume, \\(y-y_{t-1} = \\Delta y\\)\n\\[\\Delta y = \\alpha + (\\phi_1 -1)y_{t-1}+ \\epsilon_t\\] We will change\rthis equation slightly\n\\[\\Delta y = \\alpha + \\delta y_{t-1}+ \\epsilon_t\\] where,\r\\(\\delta = \\phi_1 -1\\)\nNow, our hypothesis changes to\n\\[H_0: \\delta = 0\\]\\[ H_1: \\delta \u0026lt; 0\\]\nThe t-statistics is calculated via the same formula that we use in\rlinear regression which is:\n\\[t_{\\hat{\\delta}} = \\frac{\\hat{\\delta}}{se(\\hat{\\delta})} \\tag{2}\\] We\rwill compare the t-statistics that we get from \\(Equation2\\) and compare\rit with the critical value. The only different thing is we will compare\rthe critical value with the Dickey-Fuller Distribution Table which can\rbe seen on the below figure.\n\nIf the calculated t-statistics is less then the critical value, we\rreject the null hypothesis stating that the time-series is stationary.\nThe Augmented Dickey-Fuller Test follows the same method instead the\requation becomes:\n\\[y_t=\\alpha+\\sum_{i=1}^{p}\\phi_iy_{t-i}+\\epsilon_t \\tag{3}\\]\r\\(Equation3\\) is the AR(p) model. If we follow the same procedure like\rabove for the Dickey-Fuller test we get:\n\\[\\Delta y_t = \\alpha+\\delta y_{t-1}+\\sum_{i=1}^{p}\\beta_{i}\\Delta y_{t-i} +\\epsilon_{t}\\]\rOur Null and Alternative hypothesis remains the same and we calculate\rthe test statistics for the \\(\\delta\\)\n\rExcel Demo\rI know, the title sounds very old. But, the whole purpose of doing this\rin excel is to understand the basic core concept of the Dickey-Fuller\rTest. I will be performing the Dickey-Fuller test on AR(1) model. The\rdata is randomly generated using the statsmodel package in Python.\nThe demo video can be found at: https://youtu.be/R-WVz9YiaN8\nOr simply, click on the picture below.\n\n\rPython Demo\rWe will also use the same data (data used in Excel) for the ADF test in\rPython.\nimport pandas as pd\rimport numpy as np\rfrom statsmodels.tsa.arima_process import ArmaProcess #for data generation\rfrom statsmodels.tsa.stattools import adfuller #adf test\r# Assigning random coefficient ar1 = np.array([1, -0.9])\r# Since we are generating AR1 data the MA part remains constant\rma1 = np.array([1])\rar_obj = ArmaProcess(ar1, ma1)\rnp.random.seed(112233)\r# Simulate the Data\rsimulate_ar1 = ar_obj.generate_sample(nsample=50)\r# Convert the data to pandas data-frame\rsim_ar1 = pd.DataFrame({\u0026#39;data\u0026#39;: simulate_ar1})\r\radf_test_ar1 = adfuller(sim_ar1[\u0026#39;data\u0026#39;])\rprint(f\u0026quot;The t-stat is: {adf_test_ar1[0]}\u0026quot;)\r## The t-stat is: -3.172943627520224\rprint(f\u0026quot;The p-value is: {adf_test_ar1[1]}\u0026quot;)\r## The p-value is: 0.021605203198304446\rFrom the above result, we saw that the p-value is less than 0.05 which\rmeans we reject the null hypothesis stating that the series is\rstationary.\nIn conclusion, ADF test is the first step taken in any time-series\rmodeling. ADF test being a statistical test makes sure that the data\rthat we working on follows the basic assumption of stationarity or not.\rIn this article, we saw the basic math behind the DF and expanded it to\runderstand ADF. We also implemented the demo in Excel as well as further\rvalidated the same results in Python.\n\r","date":1667692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667692800,"objectID":"03772e7de8fb747218ec309ac2c9f408","permalink":"https://sharmajee499.netlify.app/post/adf_test/","publishdate":"2022-11-06T00:00:00Z","relpermalink":"/post/adf_test/","section":"post","summary":"Stationarity is one of the major concept that needed to be understood in\rorder to model any time series. The\rWikipedia\rdefines stationary process as ‚Äúa stochastic process whose unconditional\rjoint probability distribution does not change when shifted in time.","tags":null,"title":"Stationarity and ADF Test","type":"post"},{"authors":null,"categories":null,"content":"","date":1662768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662768000,"objectID":"b2c3c17d2634d0af7f60aeb0bcdaabc5","permalink":"https://sharmajee499.netlify.app/project/telemarketing_sales/","publishdate":"2022-09-10T00:00:00Z","relpermalink":"/project/telemarketing_sales/","section":"project","summary":"Predictive Model with Explanability and Decision-Support App For Telemarketing Sales.","tags":["Demo"],"title":"Telemarketing Success Prediction","type":"project"},{"authors":null,"categories":null,"content":"\rThe class imbalance problem is very common scenario that we encounter in\rvarious domains like Churn Analysis in HR, Fraud Analysis in Finance,\rCustomer Retention in Marketing. Class Imbalance simply means that in\rour multi-class target variable the proportion are not equally close to\reach other. For instance, in dichotomous classification problem to find\rfraudulent transactions our data might have 10 fraudulent transactions\rout of 100, which is very common, considering the nature of the problem.\rSo, in simple terms, there are more observation for one class as\rcompared to another.\nNow, the question is why class imbalance is a problem in data science\rand what are its effects? As, we all know, the core working principle of\rthe any classification algorithm is to find a decision boundary to\rseparate the two class (I will take binary classification as default in\rall part of the blog). The algorithms learn from the data to find the\roptimal boundary. When we have more observations on one class, our\ralgorithms identify the pattern for that majority class but not for the\rminority class. Therefore, the algorithms learn various pattern for the\rmajority class and might perform well for that one. However, on the\rother hand, for minority class, it will struggle.\nThere are various techniques to mitigate the class-imbalance problem.\rSome of them are Oversampling, Under-Sampling, Cost-Sensitive\rAlgorithms, SMOTE (Synthetic Minority Over-Sampling Techniques) (Chawla\ret al., 2002). In this blog, we will particularly talk about the SMOTE\rwhich is probably one of the widely used techniques in resolving the\rclass-imbalance problem. I am specifically going to talk about the\rprocedure, the common mistakes, and pitfalls as well as the right way to\rSMOTE.\nI will implement all the process in Python. So, let‚Äôs get started.\nImport the Libraries\rimport pandas as pd\rimport numpy as np\rimport matplotlib.pyplot as plt\rfrom imblearn.datasets import fetch_datasets\rfrom collections import Counter\rfrom sklearn.model_selection import train_test_split\rfrom sklearn.linear_model import LogisticRegression\rfrom imblearn.over_sampling import SMOTE\rfrom sklearn.metrics import roc_auc_score\rfrom sklearn.metrics import classification_report\rfrom sklearn.metrics import confusion_matrix\rfrom sklearn.metrics import ConfusionMatrixDisplay\rfrom imblearn.under_sampling import RandomUnderSampler\rfrom imblearn.pipeline import Pipeline\r\rLoad the dataset\rIn this blog, we will utilize the Abalone Data Set that can be found at\rthis link on UCI\rwebsite. It is also pre-attached to the imblearn package, so we will\rfetch from the api itself.\n\r# Get the \u0026#39;Abalone\u0026#39; Data\rdf = fetch_datasets()[\u0026quot;abalone\u0026quot;]\r# Seperate the feature and target\rX, y = df.data, df.target\r# Count the target-class print(Counter(y))\r## Counter({-1: 3786, 1: 391})\rFrom the above output, you can see that there are two classes [-1,1] and\rwe can clearly see the imbalance targets.\nWe will then divided the data into train-test set for validation and\revaluation.\n\rTrain-Test Split\rX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,\rstratify=y, random_state=112233)\rPitfall Alert: One of the common mistakes, we all do is not to\rstratify the train and test set. In the balanced dataset, it wouldn‚Äôt\rmatter but in imbalance dataset it will have profound impact. If we\renable the stratify in the train_test_split function, it will keep\rthe same proportion of the classes in the both train and test set. This\rstratification gives the unbiased split for training as well as testing.\nLet‚Äôs verify that by checking the proportion of the test and train set.\ntrain_counter = Counter(y_train)\rtrain_prop = [(i, train_counter[i]/len(X_train) * 100) for i in train_counter]\rprint(f\u0026quot;The train data prop: {train_prop}\u0026quot;)\r## The train data prop: [(-1, 90.63154744088597), (1, 9.368452559114038)]\rtest_counter = Counter(y_test)\rtest_prop = [(i, test_counter[i]/len(X_test) * 100) for i in test_counter]\rprint(f\u0026quot;The test data prop: {test_prop}\u0026quot;)\r## The test data prop: [(-1, 90.66985645933015), (1, 9.330143540669857)]\r\rLogistic Regression (No SMOTE)\rFirst of all, we will train the model without SMOTE so that we can\rcompare and contrast the effect of SMOTE on the results. I choose to go\ralong with Logistic Regression (LR) as it is one of the famous and easy\rto understand. However, the purpose of the blog is to compare the result\rdifference before and after SMOTE, not the modeling algorithm. You can\rtry with another one to experiment on your own.\nlr_noSmote = LogisticRegression(random_state=112233).fit(X_train, y_train)\r\rLogistic Regression (With SMOTE)\rSMOTE\rPitfall Alert: In some of the class project, I have witnessed a\rbasic problem while performing SMOTE. They applied the SMOTE on the\rwhole dataset. You should only apply SMOTE after splitting the dataset,\rnot on the whole raw dataset. Otherwise, we have a problem of the\rdata-leakage. So, make sure you only apply the SMOTE or any other\rsampling techniques to the split train set.\nThere and various sampling_strategy in the SMOTE function while\roversampling the minority class. I have used the sampling_strategy as\r0.3 which means the minority and the majority proportion after smoting\rwill be the 0.3. Please, refer to the imblearn api for more detailed\rexplanation on different sampling_strategy. I choose 0.3 arbitrarily\rhowever, for optimal modeling we can tune this parameter and see what\rgives us better performance.\nsm = SMOTE(random_state=112233, sampling_strategy=0.3)\rX_res, y_res = sm.fit_resample(X_train, y_train)\rprint(\u0026#39;Original Data: \u0026#39;, Counter(y_train))\r## Original Data: Counter({-1: 3028, 1: 313})\rprint(\u0026#39;Smoted Data: \u0026#39;, Counter(y_res))\r## Smoted Data: Counter({-1: 3028, 1: 908})\r\rModel\rWe are fitting the Logistic Regression model with our resampled data.\nlr_smote = LogisticRegression(random_state=112233).fit(X_res, y_res)\r\r\rComparing the SMOTE and NON-SMOTE model\rLet‚Äôs bring the two models to the battle-ground and see if there is any\rimprovements. We will use the ROC-AUC score to compare different models.\rIt is advised for imbalance dataset accuracy is not the right metric as\rit can be biased and gave false interpretation.\n# No-SMOTE model\ry_pred_nosmote = lr_noSmote.predict(X_test)\rprint(\u0026#39;Accuracy (No Smote): \u0026#39;,lr_noSmote.score(X_test, y_test))\r## Accuracy (No Smote): 0.9066985645933014\rprint(\u0026#39;AUC Score (No Smote): \u0026#39;, roc_auc_score(y_test, y_pred_nosmote))\r## AUC Score (No Smote): 0.5\rprint(\u0026#39;Confusion Matrix (No Smote): \u0026#39;, \u0026quot;\\n\u0026quot;,confusion_matrix(y_test, y_pred_nosmote, labels=lr_noSmote.classes_), \u0026#39;\\n\u0026#39;)\r# SMOTE Model\r## Confusion Matrix (No Smote): ## [[758 0]\r## [ 78 0]]\ry_pred_smote = lr_smote.predict(X_test)\rprint(\u0026#39;Accuracy (SMOTE): \u0026#39;,lr_smote.score(X_test, y_test))\r## Accuracy (SMOTE): 0.8576555023923444\rprint(\u0026#39;AUC Score (SMOTE): \u0026#39;,roc_auc_score(y_test, y_pred_smote))\r## AUC Score (SMOTE): 0.6167207902036398\rprint(\u0026#39;Confusion Matrix (SMOTE): \u0026#39;, \u0026quot;\\n\u0026quot;, confusion_matrix(y_test, y_pred_smote, labels=lr_smote.classes_))\r\r## Confusion Matrix (SMOTE): ## [[692 66]\r## [ 53 25]]\rFrom the above comparison, we can clearly see that the model where SMOTE\ris applied performed better then the without SMOTE one. We have\rincreased the AUC score as well as we have also correctly classified\rmore number of minority class. In the plain data, we correctly\rclassified the majority class but our model couldn‚Äôt separate any of the\rminority class. On the other hand, the SMOTED model, was able to\rseparate 25 minority class in expense of majority class errors.\nPitfall Alert: Don‚Äôt compare the model performance with accuracy\rmetric for the imbalanced dataset. Our SMOTED model‚Äôs accuracy has\rdecreased but that doesn‚Äôt mean the model isn‚Äôt better then the plain\rmodel. Let‚Äôs take the same example of the our fraudulent detection. If\rwe implement plain model like above we identified all the non-fraudulent\ractivity but none of the fraudulent activity. Does that solve our main\rproblem which is to identify fraudulent activity? Absolutely No.\rHowever, the SMOTED model is able to identify more fraudulent activity\ras compared to plain one. So, which model will you choose for\rproduction? I am sure you all are deviated towards the SMOTED one.\nNow, will you be surprised if I tell you that is not the right way to\rSMOTE? Then, get ready to be surprised.\n\rSMOTE: The Right Way\rIn the original paper by Chawla et.al (2002), they performed their\rcomparision by combining oversampling with SMOTE and then under-sampling\rthe majority class. However, in many of the paper and projects, what I\rhave seen is that most of them have only used over-sample with SMOTE but\rhaven‚Äôt done under-sample.\nIn the below also, the over-sampling strategy remains the same - 0.3. In\rthe under-sample, I choose the strategy to be 0.5 meaning, the ratio of\rmajority and minority will be 0.5. Our new mixed method will have fewer\rdata-points then the SMOTED model because we under-sampled after the\rSMOTE.\n\r# Over-Sample\ros = SMOTE(random_state=112233, sampling_strategy=0.3)\r# Under-Sample\rus = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)\r# Pipeline\rpipe = Pipeline(steps = [(\u0026#39;over\u0026#39;, os), (\u0026#39;u\u0026#39;, us)])\r# New train Dataset\rX_mix, y_mix = pipe.fit_resample(X_train, y_train)\r# Count of the new data\rprint(Counter(y_mix))\r# Modeling\r## Counter({-1: 1816, 1: 908})\rlr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)\r# Prediction\ry_pred_mix = lr_mix.predict(X_test)\r# Metrices\rprint(\u0026#39;Accuracy: \u0026#39;,lr_mix.score(X_test, y_test))\r## Accuracy: 0.812200956937799\rprint(\u0026#39;AUC Score: \u0026#39;,roc_auc_score(y_test, y_pred_mix))\r## AUC Score: 0.7181685948176714\rprint(\u0026#39;Confusion Matrix: \u0026#39;,\u0026quot;\\n\u0026quot;,confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_))\r## Confusion Matrix: ## [[632 126]\r## [ 31 47]]\rBelow is the table that compare the plain, smoted and mixed model\rresult:\n\r\r\r\rModel\rAUC Score\rCorrectly Classified Minority Class\r\r\r\rPlain\r0.5\r0/78\r\rSMOTE only\r0.61\r25/78\r\rSMOTE + Under-Sample\r0.81\r47/78\r\r\r\rAs you can see from the result, our dataset is decreased. However, with\rthis fewer data points also, we have substantial increased the AUC\rscore. The model was able to classify more minority class. So, it is\rclear that over-sample with SMOTE followed by under-sample performs\rbetter. I want to reiterate that the test data are same across all the\rmodels that we compared. So, why this works? I am copying the answer\rfrom the original paper, ‚ÄúOur method of synthetic over-sampling works\rto cause the classifier to build larger decision regions that contain\rnearby minority class points.‚Äù.\n\rFinal Notes\rExtension of the SMOTE\r\rThere are various extension of SMOTE that works on the variety of\rdataset. For the dataset containing mix of categorical and numeric\rvariable there is SMOTE-NC. I would suggest to look at the imblearn\rofficial API for more variety and apply the extension that fits your\rscenario.\nSMOTE in Real-World Application\r\rIn the recent paper by Tarawneh et al.(2022), they empirically showed\rthat the variety of over-sampling techniques including SMOTE and it‚Äôs\rextensions, are deceptive and could lead to severe failure in real-world\rapplication. They found that, when the datasets were changed it produced\rintolerable number of errors.\nIs SMOTE needed?\r\rOne study by Elor \u0026amp; Averbuch-Elor (2022) demonstrated that balancing\rwith SMOTE could be beneficial for the weak classifier but not for the\rstrong ones. This means, we might see some improvements in the results\rwith SMOTE if applied to simpler algorithms like Logistic Regression,\rDecision Tree, Naive Bayes but we might not see those improvement if\rensemble or complex algorithms like Catboost, XGBoost etc are used. In\rtheir experiment, the Catboost without balancing outperformed the\rbalanced one.\nSo, should we use SMOTE? The answer is, ‚Äúit depends‚Äù. As answer to many\rData Science question, we have to experiment and see how it reacts to\rour scenario. Experiment with different methods and see what gives you\roptimal result.\n\rReferences\rChawla, N. V., Bowyer, K. W., Hall, L. O., \u0026amp; Kegelmeyer, W. P. (2002).\rSMOTE: Synthetic minority over-sampling technique. Journal of Artificial\rIntelligence Research, 16, 321‚Äì357. https://doi.org/10.1613/jair.953\nElor, Y., \u0026amp; Averbuch-Elor, H. (2022). To SMOTE, or not to SMOTE?\rArxiv.Org. http://arxiv.org/abs/2201.08528\nTarawneh, A. S., Hassanat, A. B., Altarawneh, G. A., \u0026amp; Almuhaimeed, A.\r(2022). Stop Oversampling for Class Imbalance Learning: A Review. IEEE\rAccess, 10, 47643‚Äì47660. https://doi.org/10.1109/ACCESS.2022.3169512\n\r","date":1650067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650067200,"objectID":"38d6f2d9cd63b6952cf89e1ed127f70b","permalink":"https://sharmajee499.netlify.app/post/smote/","publishdate":"2022-04-16T00:00:00Z","relpermalink":"/post/smote/","section":"post","summary":"The class imbalance problem is very common scenario that we encounter in\rvarious domains like Churn Analysis in HR, Fraud Analysis in Finance,\rCustomer Retention in Marketing. Class Imbalance simply means that in\rour multi-class target variable the proportion are not equally close to\reach other.","tags":null,"title":"Are we SMOTING correctly?","type":"post"},{"authors":null,"categories":null,"content":"\rThe notion of Regularization arises because of overfitting. So, let‚Äôs\rstart with overfitting then. I will keep aside all fancy definition.\rOverfitting simply means when your model does good on the training data\rbut performs poor on the testing data. In other words, the inadequacy of\rmodel to be generalized. The regularization adds the penalty term to\rreduce the overfitting.\nIn Statistical Learning/Machine Learning there are in general 2 kinds of\rRegularization. They are as follows:\n1. Ridge Regression (L2 Regularization)\rThese regularization techniques follow the same procedure to find the optimal weights\ras discussed in Gradient Descent.\rThe only difference is, we add the penalty/regularized term on the cost\rfunction. In particular we add:\r\\[\\lambda \\sum_{j=1}^n \\theta_{j}^2 \\tag{1}\\]For instance, if we take\rthe simple Linear Regression with MSE (Mean Squared Error) as our cost\rfunction then the cost function with regularization will look like:\r\\[\\text{Error}=\\frac{1}{n}\\sum_{i=1}^n\\bigg((y_{i} - \\sum_{j =0}^p \\theta_{j}x_{ij})\\bigg)^2 + \\lambda \\sum_{j=1}^n \\theta_{j}^2\\]\nIn this equation, \\({x_{10}, x_{20}, \\ldots, x_{n0} = 1}\\). The same\rformula can be represented in this way too:\r\\[\\frac{1}{n} \\sum_{i=1}^n \\bigg(y_{i}-\\theta_{0}-\\sum_{j=1}^p \\theta_{j}x_{ij}\\bigg)^2 + \\lambda \\sum_{j=1}^n \\theta_{j}^2\\].\rThese are just different way of saying the same thing just to confuse\rnovice people and also to make it look fancy. Forget all those fancy\rformula just remember:\r\\[\\frac{1}{\\text{number of obs.}}\\bigg(\\text{truth} - \\text{predicted}\\bigg)^2 + \\text{regularization penalty}\\]\rThis is much easier. As we already know, \\(\\theta\\)‚Äôs are the\rweight/coefficients. You might noticed or not but our weights starts\rwith \\(\\theta_{0}\\). Weights are the vector that looks like\r\\([\\theta_{0},\\theta_{1},\\ldots,\\theta_{n}]\\). If you put close attention\rto \\(Eq1\\), you see that we are summing the weights from \\(\\theta_{1}\\),\rexcluding \\(\\theta_{0}\\) in the regularization penalty term. I found very straight forward reason in ISLR\rBook,‚ÄúWe want\rto shrink the estimated associations of the each variable with the\rresponse; however, we do not want to shrink the intercept, which is\rsimply a measure of the mean value of the response when\r\\(x_{i1} = x_{i2} = \\ldots = x_{ip} = 0\\).‚Äù\nNow, the general question is why the regularization works better than\rthe simple regression methods. The reason lies in the bias-variance\rtradeoff. Bias-Variance tradeoff could be a whole new topic, but I\rwill try to explain it in as minimal as possible. You can check out\rthis for\rmore info.\nTake a instance, where you have a overfitted linear model, meaning the\rresponse and the predicted are close to linear in training data but poor\ron the testing data. This means the model has high variance and low\rbias. So, in order to decrease the variance, we introduce small bias.\rSmall increase in bias can decrease the large variance. Therefore, the\rridge regression or regularization performs better when we have high\rvariance in our model. I know, you lost me in this paragraph but we will\rdiscuss this thing much more in details on our future post.\nYou may have noticed that in the Ordinary Least Square (OLS) regression,\rscaling doesn‚Äôt have any effect on the \\(\\beta\\). (Please note, I am\rtaking about OLS. Regression using Gradient Descent should be scaled for\refficient convergence). However, for the Ridge Regression the data has\rto be scaled to get the correct intrepretable results. So, scale the\rdata before performing Ridge Regression or any regularization.\n\r2. Lasso Regression (Least Absolute Shrinkage and Selector Operator/ L1 Regularization)\rOne obvious disadvantage of the Ridge regression is that, ridge\rregression includes all predictor/features in the final model. This\rmight not be the problem in term of accuracy however might give hard\rtime in interpreting the results. With the increasing value of the\r\\(\\lambda\\), the magnitudes of the coefficient reduces but never reaches\rto zero. Therefore, the LASSO regression comes to rescue. In LASSO\rregression we add, the following penalized term to the cost function:\r\\[\\lambda \\sum_{j=1}^{p}|\\theta_{j}|\\]Instead of squaring the betas, in\rL1 we take the absolute value of the coefficients and sum them. Similar\rto the ridge regression, LASSO also shrinks the coefficients/weights\rtowards zero. However, LASSO also can force some coefficients estimates\requal to be zero when the tuning parameter is sufficiently large.\nWe have heard and may be utilized the step-wise regression to do the\rvariable selection. In the similar manner, LASSO can be used to perform\rthe variable selection. Therefore, the model generated by the LASSO are\reasily interpretable as compared to Ridge.\nNow, as we already know that majority of the model performance depended\rupon the right selection of \\(\\lambda\\). We choose a grid of \\(\\lambda\\)\rvalues and then compute the cross-validation error for each value of\r\\(\\lambda\\) to get optimal value of \\(\\lambda\\).\nThere is also third variation of the regularization that combine both L1\rand L2. It is called Elastic Net. The formula for the elastic net looks\rlike:\r\\[\\frac{1}{n}\\sum_{i=1}^n\\bigg((y_{i} - \\sum_{1}^p \\beta_{j}x_{ij})\\bigg)^2 + \\lambda_{1} \\sum_{j=1}^n \\theta_{j}^2 + \\lambda_{2} \\sum_{j=1}^{p}|\\theta_{j}|\\]\n\rWhy LASSO can make the coefficients/weights zero but Ridge cannot?\rMajority of time, people have explained above question with the below\rfigure which I extracted from ISLR book.\nIn simple explanation, the contour is our cost function and diamond (L1)\rand circle (L2) are our regularization constrains. From the ISLR\rbook,‚ÄúThe Ridge regression has a circular constrains with no sharp\rpoints which will not occur on the axis so the estimates will be\rexclusively zero. However, for Lasso, because of the corners at each of\rthe axis, the ellipse often intersect the constrain region at an axis\rmaking the coefficients zero.‚Äù Please refer to the ISLR book or\rthis article for\rin-depth explanation.\nI know, it took me a long time to understand this concept too. However,\rthere is another angle to look at the same explanation. I have made a\rsmall video that will help you to understand the same concept with\rdifferent approach.\nPlease, check out this link or click on the below\rpicture to watch video.\n\nReferences\rJames, G., Witten, D., Hastie, T., \u0026amp; Tibshirani, R. (2013). An\rintroduction to statistical learning (1st ed.) [PDF]. Springer.\n\r\r","date":1650067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650067200,"objectID":"5e2729bd945827ca6383c161f904eed6","permalink":"https://sharmajee499.netlify.app/post/regularizations/","publishdate":"2022-04-16T00:00:00Z","relpermalink":"/post/regularizations/","section":"post","summary":"The notion of Regularization arises because of overfitting. So, let‚Äôs\rstart with overfitting then. I will keep aside all fancy definition.\rOverfitting simply means when your model does good on the training data\rbut performs poor on the testing data.","tags":null,"title":"Regularizations","type":"post"},{"authors":null,"categories":null,"content":"\r\rIn my last post, I described the math behind the Gradient Descent. In there, I explained about the definition, working principles and how does it works in terms of Multiple Linear Regression. You can check out the article through this link\nIn this video, which can be accessed via this link, I explained how the Gradient Descent works in order to solve the Multiple Regression Problem.\n","date":1645833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645833600,"objectID":"8849cd1cb61ff82bd1dff5f5cd69989b","permalink":"https://sharmajee499.netlify.app/post/gradient_descent_excel/","publishdate":"2022-02-26T00:00:00Z","relpermalink":"/post/gradient_descent_excel/","section":"post","summary":"In my last post, I described the math behind the Gradient Descent. In there, I explained about the definition, working principles and how does it works in terms of Multiple Linear Regression.","tags":null,"title":"Understanding Gradient Descent Using Excel","type":"post"},{"authors":null,"categories":null,"content":"\r\rGradient descent is one of the most popular optimization algorithms in the data science and machine learning.\nFor definition, as always, I investigated the Wikipedia. It says, ‚ÄúIn mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiate function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent.‚Äù Now, let me break down the key words from the definition to make ease.\nGradient: Gradient is like a slope. It is the rate of change. The only difference is, slope term is used when there are two variables i.e., x and y, whereas the gradient is applicable in multi-dimensions. Moreover, slope is a scalar whereas gradient is vector\nFirst-Order: It only considers the first derivative when performing the update on the parameter.\nLocal Minimum: The lowest point of the function. For instance, if the function looks like a parabola facing upward, lowest point is where your function outputs minimum value for a given x.\nDifferentiable Function: It means we should be able to calculate the derivative of the given function. It sounds obvious. However, if you want to know what kind of function are differentiable, check out this website.\nOpposite Direction of Gradient: Since our objective is to find the minimum point, we travel in the opposite direction of the gradient. If we have to reach to the maximum point, we would have travelled in the direction of the gradient.\nIterative: It means finding minimum value by repeating the process until some criteria is met. The criteria can be number of iterations, change is gradient etc. depending upon the problem.\nThe above whole thing can be summarized by the picture in the top:\nWoof, that‚Äôs a lot of definition and introduction. Now,let‚Äôs move over the application side. We will solve the problem of multiple regression using the Gradient Descent.\nFirst, let‚Äôs start with the hypothesis. As we all know the general hypothesis of the linear regression in Ordinary Least Square Method is:\n\\[ h(x) = \\beta_{0} + \\beta_{1}x_{1} + \\ldots+\\beta_{n}x_{n} \\tag{1}\\] However, we are going to change this equation with different machine learning notation, but the essence remains the same.\n\\[ h(x) = \\theta_{0}x_{0}+\\theta_{1}x_{1}+\\ldots+\\theta_{n}x_{n} \\tag{2}\\] where \\(x_{0} = 1\\) and \\(x_{1},x_{2},\\ldots,x_{n}\\) are the multiple input values.\nThis \\(Equation2\\) can be changed into the matrix notation which will look like: \\[ h_{\\theta}(x) = \\theta^{T}x \\tag{3}\\] \\(x = [x_{0},x_{1},\\ldots,x_{n}]\\) and \\(\\theta = [\\theta_{0},\\theta_{1},\\ldots,\\theta_{n}]\\)\nThe whole purpose of the optimization algorithms is to find the optimal value. But what is the optimal situation for the Linear Regression Problem. It is finding the minimum error possible while modeling. In other words, finds the values of \\(\\theta\\) , such that it will give us the lowest error possible.\nNow, from the statistics class you may have heard about the Mean Squared Error (MSE). As the word says itself, it is the average of the squared error/residuals. The formula for the MSE is\n\\[ MSE = \\frac{1}{m}\\sum_{i=1}^{m}\\bigg[h_{\\theta}(x^{(i)}) - y^{i} \\bigg]^2 \\tag{4}\\] In the Machine Learning lingo, we call this Loss Function which is modified further:\n\\[J(\\theta_{0},\\theta_{1},\\ldots,\\theta_{n}) = \\frac{1}{2m}\\sum_{i=1}^m \\bigg[h_{\\theta}(x^{(i)}) - y^{i} \\bigg]^2 \\tag{5}\\]\rNow, let‚Äôs look at the update rule, meaning how should we change \\(\\theta\\) according to the gradient. As you can see, there is extra constant 2, which is introduced because it makes easier in taking derivatives.\n\\[ \\theta_{j} := \\theta_{j} - \\alpha \\frac{\\partial}{\\partial\\theta_{j}}J(\\theta) \\tag{6}\\]\rAs we see, we introduced a new term \\(\\alpha\\) which is called learning rate. Learning rate is a hyper-parameter for the step size while climbing down the hill. Check this link for more info on learning rate.\nFor the understanding purpose, let‚Äôs first apply the update rule for \\(\\theta_{0}\\) only. The derivative is going to look like:\n\\[\\text{Substituiting eq5 in eq6, we get}\\]\n\\[\\theta_{0} = \\theta_{0} - \\alpha \\frac{\\partial \\bigg(\\frac{1}{2m} \\sum_{i=1}^{m} \\big[h_{\\theta}(x^{(i)}) - y^{(i)} \\big] \\bigg)^2}{\\partial \\theta_{0}} \\]\n\\[\\text{Using Chain Rule}\\]\n\\[\\theta_{0} = \\theta_{0} - \\alpha \\bigg(\\frac{2}{2m} \\sum_{i=1}^{m} \\big[h_{\\theta}(x^{(i)}) - y^{(i)} \\big] \\bigg) \\partial \\frac {(h_{\\theta}(x^{(i)}) - y^{(i)})} {\\partial\\theta_{0}} \\]\n\\[\\theta_{0} =\\theta_{0} - \\alpha \\bigg(\\frac{1}{m} \\sum_{i=1}^{m} \\big[h_{\\theta}(x^{(i)}) - y^{(i)} \\big] x_{0}^{(i)} \\bigg) \\tag{7}\\]\nNow, you must be wondering how we went to final step from second last step. Let me break it down for you:\n\\[ \\partial \\frac {(h_{\\theta}(x^{(i)}) - y^{(i)})} {\\partial\\theta_{0}} \\]\n\\[\\text{From eq2, we can replace the } h_{\\theta}(x^{(i)}) \\text{ and we will take example for single row only}\\]\n\\[\\frac{\\partial \\big (\\theta_{0}x_{0} + \\ldots + \\theta_{n}x_{n} - y \\big)}{\\partial \\theta_{0}}\\]\n\\[=\u0026gt; x_{0} \\]\nAll part that doesn‚Äôt contain \\(\\theta_{0}\\) are constant so, derivative with respect to \\(\\theta_{0}\\) will give zero output.\nThis is just for the single observation, however for all observation it takes the form of the \\(eq7\\).\nMultiple Linear Regression Using Gradient Descent\nThe same concept applies to the Multiple Linear Regression. Instead of doing it for only \\(\\theta_{0}\\), we will do it for several variables.\nThe Gradient descent formula or update rule looks like:\n\\[ \\text{repeat until convergence :}\\]\n\\[\\theta_{0} = \\theta_{0} - \\alpha \\bigg(\\frac{1}{m} \\sum_{i=1}^{m}\\big[h_{\\theta}(x^{(i)}) - y^{(i)} \\big]x_{0}^{(i)} \\bigg) \\]\n\\[\\theta_{1} = \\theta_{1} - \\alpha \\bigg(\\frac{1}{m} \\sum_{i=1}^{m}\\big[h_{\\theta}(x^{(i)}) - y^{(i)} \\big]x_{1}^{(i)} \\bigg) \\]\n\\[\\vdots \\]\n\\[\\theta_{n} =\\theta_{n} - \\alpha \\bigg(\\frac{1}{m} \\sum_{i=1}^{m} \\big[h_{\\theta}(x^{(i)}) - y^{(i)} \\big]x_{n}^{(i)} \\bigg)\\]\nHere, \\(\\text{repeat untill convergence}\\) means updating the \\(\\theta\\)‚Äôs until some iteration (epochs) or criteria are reached.\nThis is just the tip of the Gradient Descent as it has wide application to offer. There are different types of Gradient Descent like Stochastic, Mini-batch which are more popular than the Batch Gradient Descent (Vanilla).\nUnderstanding of Gradient Descent is must in the field of data science/machine learning. I hope this article was helpful to build some intuition behind the working principle. I am not using any code because there are different popular library that does those jobs.\nIf you want to understand the working of Gradient Descent in Excel, please check out this link\nReferences\rImage Link: https://towardsdatascience.com/stochastic-gradient-descent-explained-in-real-life-predicting-your-pizzas-cooking-time-b7639d5e6a32\nWikimedia Foundation. (2022, February 15). Gradient descent. Wikipedia. Retrieved February 24, 2022, from https://en.wikipedia.org/wiki/Gradient_descent\nG√©ron, A. (2020). Hands-on machine learning with scikit-learn, Keras, and tensorflow: Concepts, tools, and techniques to build Intelligent Systems. O‚ÄôReilly.\nMani, A. (2019, December 1). Solving multivariate linear regression using gradient descent. Atma‚Äôs blog. Retrieved February 24, 2022, from https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\nGunjal, S. (2020, May 13). Multivariate linear regression from scratch with python. Quality Tech Tutorials. Retrieved February 24, 2022, from https://satishgunjal.com/multivariate_lr/\n\r","date":1645574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645574400,"objectID":"bf2f741b07590af74e3c6fe8b8c54ff9","permalink":"https://sharmajee499.netlify.app/post/gradient_multiple_regression/","publishdate":"2022-02-23T00:00:00Z","relpermalink":"/post/gradient_multiple_regression/","section":"post","summary":"Gradient descent is one of the most popular optimization algorithms in the data science and machine learning.\nFor definition, as always, I investigated the Wikipedia. It says, ‚ÄúIn mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiate function.","tags":null,"title":"Math Behind Linear Regression: Gradient Descent","type":"post"},{"authors":["Sandesh Sharma","Dr. Christopher M Castille","Dr. Ann-Marie R Castille"],"categories":null,"content":"","date":1639094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639094400,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://sharmajee499.netlify.app/publication/journal-article/","publishdate":"2021-12-10T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Insufficient effort responding (IER) is a common concern of survey researchers especially those who collect data through crowdsourcing. Methods of controlling for IER may be overt (identifiable by respondents) or covert. This study examines the relative impact of controlling for covert IER when overt-IER methods are in the survey design. Using data from an experiment on performance feedback reactions where overt IER controls were in place, we examine the scale reliabilities and convergent and discriminant validity, both of which change negligibly by controlling for covert IER. Findings suggest controlling for covert IER lacks incremental value beyond controlling for overt IER.","tags":null,"title":"The Incremental Value of Controlling for Covert Insufficient Effort Responding","type":"publication"},{"authors":null,"categories":null,"content":"\r\rWe all have heard about the Linear Regression from our basic statistics class or some newspaper or somewhere here and there. What I mean to say is that Linear Regression is one of the most common algorithm that we will see in many kinds of predictive analysis as well as finding linear relationship between the dependent and independent variables.\nIn this post, we will particularly talk about the mathematical working principal for the simple linear regression. Let me rephrase again, just Simple Linear Regression not Multiple Regression at this post. However, the concepts are similar.\nMATH ALERT\nMathematically, if we have a independent variable X and dependent variable Y, then we can write: \\[\rY \\sim \\beta_0 + \\beta_1X_i \\tag{1}\r\\] where \\(\\beta_0\\) and \\(\\beta_1\\) are the two unknown constants that represents the intercept and slope term of the linear model respectively. One can see this as the coordinates that we studied at our school level where we have slope-intercept formula as\n\\[\ry=mx+c\r\\]\nOnce we used the training data to find the coefficients we can predict the respective \\(y\\) value by the below equation \\[\r\\hat{Y}=\\hat{\\beta_0}+\\hat{\\beta_1}X\\tag{2}\r\\]\nEstimating the Coefficients\rTo find the \\(\\beta_0\\) and \\(\\beta_1\\), we must use the training data. Our goal is to find \\(\\beta_0\\) and \\(\\beta_1\\) such that the linear model fits the every available data points with minimum error as shown in the figure below. There are several approach to minimize the error between the line and the data points however, in this post we will particularly talk about the least square method.\n\rLeast Square Methods\r\nLeast square in one the most popular method to estimate the beta coefficients for the simple linear regression. Similar to the \\(Equation 2\\), we can predict value of \\(i^{th}\\) sample using the below equation. \\[\r\\hat{Y_i}=\\hat{\\beta_0}+\\hat{\\beta_1}X_i\\tag{3}\r\\] Then, \\(e_i = y_i - \\hat{y_i}\\), where \\(e_i\\) represents the residual or error of the \\(i^{th}\\) response. So our goal become to minimize the error. We square the error which makes the final equation as \\[\r{e_1}^2 = (y_i - \\hat{y_i})^2\r\\] Now for all of the data points the sum of the square of the residuals,RSS, will be \\[\rRSS = {e_1}^2+{e_2}^2+\\cdots+{e_n}^2\r\\] \\[\rRSS = (y_1 - \\hat{y_1})^2+\\cdots+(y_n - \\hat{y_n})^2 \\tag{4}\r\\] Now, substituting the value of \\(\\hat{y_i}\\) from \\(equation 2\\) to \\(equation 4\\). \\[\rRSS = (y_1-(\\beta_0+\\beta_1X_1))^2+\\cdots+(y_n-(\\beta_0+\\beta_nX_n))^2\r\\] which can also be written as \\[\rRSS = \\sum_{i=1}^n \\Big[y_i-(\\beta_0+\\beta_1X_i)^2\\Big]\r\\] In the functional notation it can be written as \\[\rf(\\beta_0,\\beta_1) = \\sum_{i=1}^n \\Big[y_i-(\\beta_0+\\beta_1X_i)^2\\Big] \\tag{5}\r\\]\nSo, to minimize the RSS or \\(Equation5\\) we will take the partial derivative with respect to \\(\\beta_0\\) and \\(\\beta_1\\) and equalize to \\(0\\) for minimization.\nFirst of all let‚Äôs take derivative with respect to \\(\\beta_0\\)\n\\[\r\\frac{\\partial (\\beta_0,\\beta_1)}{\\partial \\beta_0} = \\sum_{i=1}^n \\Big[y_i-(\\beta_0+\\beta_1X_i)^2\\Big] \\tag{5}\r\\] \\[\r\\Rightarrow \\sum2(y_i-\\beta_0-\\beta_1X_i)(-1) = 0\r\\] We took the derivative and equalize to zero.\n\\[\r\\Rightarrow -2 \\sum y_i-\\beta_0-\\beta_1X_i =0\r\\] \\[\r\\Rightarrow \\sum y_i - \\sum\\beta_0 -\\sum\\beta_1X_i =0\r\\] \\[\r\\Rightarrow \\sum y_i = n\\beta_0 +\\sum \\beta_1X_i \\] \\[\\beta_0 \\text{: is a constant so summing n time will be n times beta}\\] \\[\\Rightarrow \\frac{\\sum y_i -\\beta_1\\sum X_i}{n}=\\beta_0 \\] \\[\\Rightarrow \\frac{\\sum y_i}{n}-\\beta_1 \\frac{\\sum X_i}{n} = \\beta_0 \\] \\[\\text{We know } \\frac{\\sum y_i}{n}= \\bar{y}, \\frac{\\sum X_i}{n}=\\bar{x}\\] \\[\\beta_0 = \\bar{y}-\\beta_1\\bar{x} \\tag{6}\\] Now in a similar way we will take the derivative with respect to \\(\\beta_1\\)\n\\[\\frac{\\partial (\\beta_0,\\beta_1)}{\\partial \\beta_1} = \\sum_{i=1}^n \\Big[y_i-(\\beta_0+\\beta_1X_i)^2\\Big]\\] \\[\\Rightarrow \\sum2(y_i-\\beta_0-\\beta_1X_i)(-X_i) = 0\\] \\[\\Rightarrow \\sum X_i(y_i-(\\beta_0+\\beta_1X_i))=0 \\tag{7}\\] From \\(Equation6\\) we know that value of \\(\\beta_0\\) therefore substituting in \\(Equation7\\)\n\\[\\Rightarrow \\sum X_i(y_i-(\\bar{y}-\\beta_1\\bar{x}+\\beta_1X_i)) = 0 \\] \\[\\Rightarrow \\sum X_i(y_i-\\bar{y}-\\beta_1(X_i-\\bar{x})) =0 \\\\\\] \\[\\Rightarrow \\sum X_i(y_i-\\bar{y}) = \\beta_1 \\sum X_i(X_i-\\bar{x}) \\] \\[\\Rightarrow \\beta_1 = \\frac {\\sum X_i(y_i-\\bar{y})}{\\sum X_i(X_i-\\bar{x})} \\tag{8}\\] The \\(Equation 8\\) can be written as \\[\\beta_1 = \\frac{\\sum(X_i-\\bar{x})(y_i-\\bar{y})}{\\sum (X_i-\\bar{x})^2} \\tag{9}\\] I know there is lot of things in between the \\(Equation8\\) and \\(Equation9\\). Below I will explain how that miracle happened.\nFirst of all let‚Äôs look at the numerator of \\(Equation9\\) \\[\\sum(X_i-\\bar{x})(y_i-\\bar{y}) = \\sum X_i(y_i-\\bar{y})-\\sum \\bar{x}(y_i-\\bar{y})\\] \\[= \\sum X_i(y_i-\\bar{y})- \\bar{x}\\sum(y_i-\\bar{y})\\] \\[\\text{We know} \\sum(y_i-\\bar{y}) =0 \\] \\[\\text{The sum of the deviations from mean is zero.}\\] \\[\\sum(X_i-\\bar{x})(y_i-\\bar{y}) = \\sum X_i(y_i-\\bar{y})\\] Now again let‚Äôs look at the denominator of the \\(Equation8\\) \\[\\sum (X_i-\\bar{x})^2 = \\sum(X_i-\\bar{x})(X_i-\\bar{x})\\] \\[= \\sum X_i(X_i-\\bar{x})-\\bar{x} \\sum(X_i-\\bar{x})\\] \\[\\text{Again similar to above reason} \\sum(X_i-\\bar{x}) =0 \\] \\[ \\sum (X_i-\\bar{x})^2 = \\sum X_i(X_i-\\bar{x}) \\] Finally, after long journey of mathematics we found our two unknown variables that is \\(\\beta_0\\) and \\(\\beta_1\\). Now, with the help of \\(Equation3\\) we can predict any \\(\\hat{y}\\) for the given \\(X\\).\nIn my next posts, I will talk about estimating parameters with the Maximum Likelihood Methods as well as Gradient Descent too.\n\rReferences\rJBstatistics. (2019, March 22). Deriving the least squares estimators of the slope and intercept (simple linear regression) [Video]. YouTube. https://www.youtube.com/watch?v=ewnc1cXJmGA\nGareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. (2013). An introduction to statistical learning : with applications in R.\nDevore, J. L. (1995). Probability and statistics for engineering and the sciences. Belmont: Duxbury Press.\nImage Link: https://www.jmp.com/en_hk/statistics-knowledge-portal/what-is-multiple-regression/fitting-multiple-regression-model.html\n\r","date":1637884800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637884800,"objectID":"c5821835cd2aa8ac4f534a8659af40ca","permalink":"https://sharmajee499.netlify.app/post/math_linear_regression/","publishdate":"2021-11-26T00:00:00Z","relpermalink":"/post/math_linear_regression/","section":"post","summary":"We all have heard about the Linear Regression from our basic statistics class or some newspaper or somewhere here and there. What I mean to say is that Linear Regression is one of the most common algorithm that we will see in many kinds of predictive analysis as well as finding linear relationship between the dependent and independent variables.","tags":null,"title":"Math Behind Simple Linear Regression: Least Square Method","type":"post"},{"authors":null,"categories":null,"content":"\r\rIn this article we will discuss the basic of the data manipulation ‚Äì\rslicing and selecting. As we have seen, majority of time, we need to work\rwith a subset of the data for the analysis. We might need just need to\rwork on the description on one variable. Such situation is common in the\rdata analytics workflow. So, selection and slicing of right data in\refficient manner is an essential skill for a data analyst. The article\rwill discuss about selecting data for following data structures:\nVector\n\rList\n\rData Frame\n\r\rVectors:\nVector is the basic data-structure in R. The element of the vectors must\rbe of same data types. Meaning a vector can‚Äôt contain the mixed\rvariables like integer, string, Boolean etc. Vectors are one\rdimensional.\nFor the selection of a specific element of the vector, we simply put the\rindex number inside the big bracket. For instance, if we have to select\rthe 2nd element of vector X, our code will be X[2]. Let me remind you\rone more time, unlike other majority of programming languages, the\rindexing of R always start at 1. We will explore the details in the demo\rbelow.\n#Making some vectors\rvec1 \u0026lt;- c(11,23,34,46,51)\rvec2 \u0026lt;- c(\u0026#39;this\u0026#39;,\u0026#39;is\u0026#39;,\u0026#39;a\u0026#39;,\u0026#39;vector\u0026#39;)\rvec3 \u0026lt;- c(TRUE, FALSE, FALSE, TRUE)\r#Selecting the single values\rvec1[2]\r## [1] 23\r#selecting the multiple values\rvec1[c(2,3)] #in this example we are selecting the 2nd and 3rd element of vec1\r## [1] 23 34\r#selecting after a certain index\rvec1[1:5] #we selected everything from index 1 to 5.\r## [1] 11 23 34 46 51\rvec2[-1] # -1 will include everything except the first element\r## [1] \u0026quot;is\u0026quot; \u0026quot;a\u0026quot; \u0026quot;vector\u0026quot;\rList\nList are different than the vector because they can have multiple data\rtypes.The list are formulated by using list() instead of c() in vectors.\rList sometimes can be recursive as a list can contain list within the\rlist. I know that‚Äôs confusing but will explain on the demo below:\nlst1 \u0026lt;- list(100, 101, 102, 103, 104, 105)\rlst2 \u0026lt;- list(155, \u0026#39;program\u0026#39;, TRUE, 3.25, 200)\rlst3 \u0026lt;- list(lst1, lst2 , 534, 546, TRUE, 1.98) #the complicated list\r#selection in the plain list\rlst1[2] #this is similar to the vector\r## [[1]]\r## [1] 101\rlst2[3:5]\r## [[1]]\r## [1] TRUE\r## ## [[2]]\r## [1] 3.25\r## ## [[3]]\r## [1] 200\r#selection in the complicated one\rlst3[[2]][2] \r## [[1]]\r## [1] \u0026quot;program\u0026quot;\r#first double bracket is selecting the 2nd element of the lst3 #which is lst2, then we are selecting the 2nd element of lst2.\rlst3[[1]][2:5] \r## [[1]]\r## [1] 101\r## ## [[2]]\r## [1] 102\r## ## [[3]]\r## [1] 103\r## ## [[4]]\r## [1] 104\r#another similar example like above but we selecting from all #elements between 2nd and 5th. \rData Frame\nData Frame are the general structure that we usually see in our analysis\rproject. Think them as the Excel sheet- with the rows and columns. The proper\rmethods of selecting right data from the data frame plays a vital role in data\ranalysis.\ndata= iris #loading the iris data and saving in the \u0026#39;data\u0026#39; variable\rhead(data) #looking at the first few rows of the dataset.\r## Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## 1 5.1 3.5 1.4 0.2 setosa\r## 2 4.9 3.0 1.4 0.2 setosa\r## 3 4.7 3.2 1.3 0.2 setosa\r## 4 4.6 3.1 1.5 0.2 setosa\r## 5 5.0 3.6 1.4 0.2 setosa\r## 6 5.4 3.9 1.7 0.4 setosa\r#QUESTION 1: How do you select the value in 3rd column and 2nd row?\rrow_number = 2\rcolumn_number =3\rdata[row_number,column_number] #1.4 is our output. \r## [1] 1.4\r#QUESTION 2: How to select all the rows of the 2nd column?\rdata$Sepal.Width #the \u0026#39;$\u0026#39; sign in the easiest way to select a column.\r## [1] 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5\r## [19] 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2\r## [37] 3.5 3.6 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3\r## [55] 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8\r## [73] 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5\r## [91] 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9\r## [109] 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2\r## [127] 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2\r## [145] 3.3 3.0 2.5 3.0 3.4 3.0\r#QUESTION 3:How to select multiple column?\rdata[1:10,c(2,3)] #by indexing. Making vector of needed column.\r## Sepal.Width Petal.Length\r## 1 3.5 1.4\r## 2 3.0 1.4\r## 3 3.2 1.3\r## 4 3.1 1.5\r## 5 3.6 1.4\r## 6 3.9 1.7\r## 7 3.4 1.4\r## 8 3.4 1.5\r## 9 2.9 1.4\r## 10 3.1 1.5\rdata[1:10,c(\u0026#39;Sepal.Width\u0026#39;,\u0026#39;Sepal.Length\u0026#39;)] #by using column name\r## Sepal.Width Sepal.Length\r## 1 3.5 5.1\r## 2 3.0 4.9\r## 3 3.2 4.7\r## 4 3.1 4.6\r## 5 3.6 5.0\r## 6 3.9 5.4\r## 7 3.4 4.6\r## 8 3.4 5.0\r## 9 2.9 4.4\r## 10 3.1 4.9\r#QUESTION 4: How to select first 10 rows of 2nd and 3rd column\rdata[1:10,c(2,3)]\r## Sepal.Width Petal.Length\r## 1 3.5 1.4\r## 2 3.0 1.4\r## 3 3.2 1.3\r## 4 3.1 1.5\r## 5 3.6 1.4\r## 6 3.9 1.7\r## 7 3.4 1.4\r## 8 3.4 1.5\r## 9 2.9 1.4\r## 10 3.1 1.5\r#QUESTION 5: Select all the \u0026#39;Sepal.Length\u0026#39; that is greater than 7\rdata[data$Sepal.Length\u0026gt;7,] \r## Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## 103 7.1 3.0 5.9 2.1 virginica\r## 106 7.6 3.0 6.6 2.1 virginica\r## 108 7.3 2.9 6.3 1.8 virginica\r## 110 7.2 3.6 6.1 2.5 virginica\r## 118 7.7 3.8 6.7 2.2 virginica\r## 119 7.7 2.6 6.9 2.3 virginica\r## 123 7.7 2.8 6.7 2.0 virginica\r## 126 7.2 3.2 6.0 1.8 virginica\r## 130 7.2 3.0 5.8 1.6 virginica\r## 131 7.4 2.8 6.1 1.9 virginica\r## 132 7.9 3.8 6.4 2.0 virginica\r## 136 7.7 3.0 6.1 2.3 virginica\r#in the row we defined our condition and in column we left empty because we #needed all the columns\rIn this article, I just showed the basic of selecting data in R. Indeed,\rthese method can be made more complex to subset various data. Similar to\r‚ÄòQUESTION 5‚Äô, we can use the filter conditions to select different variety of\rdata. However, this article is intended for the people who are getting started\rwith R. I will post much advance methods in future posts.\nThank You\n","date":1636243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636243200,"objectID":"cb10df64f5f44c7db09af5ac840e2c16","permalink":"https://sharmajee499.netlify.app/post/selecting_data/basic_selecting_data/","publishdate":"2021-11-07T00:00:00Z","relpermalink":"/post/selecting_data/basic_selecting_data/","section":"post","summary":"In this article we will discuss the basic of the data manipulation ‚Äì\rslicing and selecting. As we have seen, majority of time, we need to work\rwith a subset of the data for the analysis.","tags":null,"title":"Basic of Selecting Data","type":"post"},{"authors":null,"categories":null,"content":"\r\rRecently, I was invited by couples of faculty member from Nicholls State University‚Äôs College of Business to present about the Data Analytics. The presentation was all about data analytics future, job demand, scope and resources available at College of Business. I want to thank Dr.¬†Chris Castille for arranging this opportunity. I have already given 6 presentation in the various classes like Computer Information System [CIS_231], Business Statistics [QBA_282/283], Management [MNGT_301], Marketing [MKTG_470] and Business Administration [BSAD_101]. I still have two more presentation to give which is on mid-April.\nThe video of one of my presentation given on MKTG_470 can be found on this link\nI am sorry for the audio quality of the video. I should have presented nearby the mic. There are plenty of mistakes as I was nervous as well as excited. At the end, I would like to thank the respective faculties who gave me a chance to present in their classes. In addition, I would also expand my gratitude towards the students who listened my presentation for 45 minutes. üòÉ\n","date":1617494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617494400,"objectID":"d28ef5ed31915b7eba649c8fe3c6ec17","permalink":"https://sharmajee499.netlify.app/post/data_analytics_presentation/","publishdate":"2021-04-04T00:00:00Z","relpermalink":"/post/data_analytics_presentation/","section":"post","summary":"Recently, I was invited by couples of faculty member from Nicholls State University‚Äôs College of Business to present about the Data Analytics. The presentation was all about data analytics future, job demand, scope and resources available at College of Business.","tags":null,"title":"Data Analytics Presentation","type":"post"},{"authors":null,"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://sharmajee499.netlify.app/project/external-project/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"Image classification of my and German Shepherd images using Convolution Neural Network (CNN) and Transfer Learning.","tags":["Demo"],"title":"Image Classification with Transfer Learning","type":"project"},{"authors":null,"categories":null,"content":"\r\rLogistic Regression is one of the most used classification algorithm in statistical analysis and machine learning. The interpretability of output, easy to understand concept and efficient to train makes logistic regression one of the best tool for statistical inference and prediction.\nWhy not Linear Regression?\rThe use case of Linear Regression and Logistic Regression is totally different. Linear regression is used to predict continuous set of values whereas logistic regression is used to predict binary prediction like alive or dead, yes or no, 0 or 1 etc. There are techniques to expand the logistic regression to classify multiple classes.\nLet us assume we have a dependent variable with binary class 0 and 1 in our dataset. If we use linear regression, some of our estimates might be outside [0,1] interval making them hard to interpret as probabilities.\nAs shown in the figure above, which I copied from the article in the Medium, we can see the the linear line is not fitting majority of the data points. On the other hand, the best fit line is going above 1 and below 0 making it hard to interpret the target variable. Any time a straight line is fit to a binary response that is coded as 0 or 1, the prediction can always get probabilities \u0026lt;0 or for some values and \u0026gt;1 for some values.\nLet us define \\(P(X)\\) be the linear regression function which is defined as \\(P(X) = \\beta_{0}+\\beta_{1}X\\), where \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are the coefficients of intercept and independent variable respectively.\nNow, to restrict the functions output between 0 and 1 for all values of \\(X\\), we will use logistic function which will restrict the output within the range [0,1].\n\\[P(X) = \\frac{e^{\\beta_{0}+\\beta_{1}X}}{1+e^{\\beta_{0}+\\beta_{1}X}} \\tag{1}\\] When further simplified by cross-multiplication and taking common, we will end up with\n\\[\\frac{P(X)}{1-P(X)}= e^{\\beta_{0}+\\beta_{1}X} \\tag{2}\\]\nThe left-hand side of the equation is called odds and can take any value between 0 and \\(\\infty\\). According to the dictionary Merriam-Webster, Odds simply means the probability that one thing is so or will happen rather than another. The value of odds close to 0 indicated low probabilities whereas high value indicated high probabilities.\nBy taking \\(\\log\\) on both sides of the above equation:\n\\[\\log\\left({\\frac{P(X)}{1-P(X)}}\\right)= \\beta_{0}+\\beta_{1}X \\tag{3}\\] The left-hand side is called the log-odds or logit. We see that logistic regression model has a logit that is linear in \\(X\\). In linear regression \\(\\beta{1}\\) gives the change rate in \\(Y\\) with one unit increase in \\(X\\). However, in logistic regression, increasing \\(X\\) by one unit change log odds by \\(\\beta_{1}\\).\nSince, the hurdle to restrict the value within 0 and 1 is solved, we now proceed to find the value of our coefficients.\n\rFinding the Coefficients\rThe coefficients are estimated based on the training data with mathematical equation called likelihood function. I am not going to explain this function in detail and which is also not necessary at the moment. One doesn‚Äôt have to write the function and work from bottom up, R does the stuff for you. However, I will lay down the function below:\n\\[l(\\beta_{0}, \\beta_{1}) = \\prod_{i:y_{i}=1} p(x_{i}) \\prod_{i^{\\prime}:y_{i^{\\prime}}=0} (1-p(x_{i^{\\prime}})) \\tag{4}\\]\n\rLet‚Äôs Predict\rAfter finding the \\(\\beta_{0}\\) and \\(\\beta_{1}\\), we simply plug the value of \\(X\\) for the needed prediction. We will use the logit function which is our equation 1. Since, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are estimated by the likelihood function, we plug the dependent variable i.e.¬†X which will give us the respective probability of that instance.\nThe same idea can be expanded for the multiple independent variables. For the categorical variables, the data is encoded as dummy variable. Moreover, Logistic Regression can also used to classify a response variable that has more than two classes.\n\rDemo\rIn this section, I will demonstrate the working process of logistic regression in R.\n#Installing the package suppressPackageStartupMessages(library(tidyverse)) #for data manipulation\rsuppressPackageStartupMessages(library(ISLR)) #for dataset\r## Warning: package \u0026#39;ISLR\u0026#39; was built under R version 4.0.5\r#Importing Dataset\rdata(\u0026quot;Default\u0026quot;) #dataset\r#Summerizing the data\rsummary(Default)\r## default student balance income ## No :9667 No :7056 Min. : 0.0 Min. : 772 ## Yes: 333 Yes:2944 1st Qu.: 481.7 1st Qu.:21340 ## Median : 823.6 Median :34553 ## Mean : 835.4 Mean :33517 ## 3rd Qu.:1166.3 3rd Qu.:43808 ## Max. :2654.3 Max. :73554\rWe can see that, there are 3 independent variable and our dependent variable is default which has two classes ‚ÄòYes‚Äô and ‚ÄòNo‚Äô. The total data points are 10,000. For more info, on the dataset go to this link and access the reference manual.\n#Building Model\rmodel \u0026lt;- glm(default~., family=\u0026quot;binomial\u0026quot;, data=Default)\rsummary(model)\r## ## Call:\r## glm(formula = default ~ ., family = \u0026quot;binomial\u0026quot;, data = Default)\r## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4691 -0.1418 -0.0557 -0.0203 3.7383 ## ## Coefficients:\r## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) -1.087e+01 4.923e-01 -22.080 \u0026lt; 2e-16 ***\r## studentYes -6.468e-01 2.363e-01 -2.738 0.00619 ** ## balance 5.737e-03 2.319e-04 24.738 \u0026lt; 2e-16 ***\r## income 3.033e-06 8.203e-06 0.370 0.71152 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## (Dispersion parameter for binomial family taken to be 1)\r## ## Null deviance: 2920.6 on 9999 degrees of freedom\r## Residual deviance: 1571.5 on 9996 degrees of freedom\r## AIC: 1579.5\r## ## Number of Fisher Scoring iterations: 8\rIn the model building glm() function, we started with the y value (dependent variable) connecting all dependent variable(Note: If you want to use all the columns of your data frame then just put period sign like in above code.) by tilde(~) sign. We put ‚Äòbinomial‚Äô on the ‚Äòfamily‚Äô because we are using logistic regression.\nThe summary output throws a bunch of useful information. The coefficients section give the estimated \\(\\beta\\) for the respective variable with the p-value for the significance. Let me remind you one more time, the coefficient is log odds. It is explained as, one unit increase in ‚Äòbalance‚Äô is associated with an increase in log odds of default by 0.0057.\n#Predicting the value\rpredict(model,newdata=data.frame(student=\u0026quot;No\u0026quot;,balance=1000,income=50000), type=\u0026quot;response\u0026quot;)\r## 1 ## 0.006821253\rSo, we predicted the probability of the new data that we fed into the ‚Äòpredict()‚Äô function. In the function, first we have our model, newdata and type. The ‚Äòtype‚Äô tells that we want our answer in probability. From the code, we got our predicted probability as 0.68%, which is pretty low. So, we can conclude that this instance is most likely to get a ‚ÄòNo‚Äô. Generally, the cutoff value for ‚ÄòYes‚Äô \u0026amp; ‚ÄòNo‚Äô is 50%, however this can be changed depending upon the problem.\nIn this demo, I am skipping various steps. Some of them are, splitting the data into train \u0026amp; test data to calculate the accuracy and efficiency of the model, confusion matrix, cross-validate, detailed EDA etc. The sole purpose of the article is to give you some basic theoretical concept of Logistic Regression and interpretation of results when analysis is done in R.\nAt last, if one wants to master data science, machine learning, or any analysis, logistic regression is a must known algorithm.\nNote: For the article, I was dependent upon ‚ÄúAn Introduction to Statistical Learning‚Äù book. This is by far one of the best book on getting started with data science. I highly advise to read the book.\n\rReferences\r\rhttps://towardsdatascience.com/why-linear-regression-is-not-suitable-for-binary-classification-c64457be8e28\rhttps://www.merriam-webster.com/dictionary/odds\rhttps://cran.r-project.org/web/packages/ISLR/index.html\rhttps://www.statlearning.com/\r\r\r","date":1590364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590364800,"objectID":"ee6644e4df2143cba7c51402acf5f7ab","permalink":"https://sharmajee499.netlify.app/post/logistic_regression/","publishdate":"2020-05-25T00:00:00Z","relpermalink":"/post/logistic_regression/","section":"post","summary":"Logistic Regression is one of the most used classification algorithm in statistical analysis and machine learning. The interpretability of output, easy to understand concept and efficient to train makes logistic regression one of the best tool for statistical inference and prediction.","tags":["Blogs"],"title":"Logistic Regression","type":"post"},{"authors":null,"categories":null,"content":"","date":1590364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590364800,"objectID":"0b2d3fe0acf276f06cfb9ad0c6ba4cb3","permalink":"https://sharmajee499.netlify.app/project/proj_txt/","publishdate":"2020-05-25T00:00:00Z","relpermalink":"/project/proj_txt/","section":"project","summary":"Building a machine learning model that predicts which Tweets are about real disasters and which one‚Äôs aren‚Äôt.","tags":["Demo"],"title":"Text Analytics With R.","type":"project"},{"authors":null,"categories":null,"content":"\r\rR is a beautiful and powerful programming language. People always\rdebate about the Python vs.¬†R. For me, both have advantages in their\rrespective fields. I have used Python and R for about equal amount of\rtime. Personally, I find R to be more powerful in data manipulation,\rcleaning, summarizing and making statistical models. However, Python is\rmore easy to work when it comes to deep learning and advance\rcomputational modeling. Moreover, Python is general purposed programming\rlanguage meaning, it could be used to make anything. I mean anything\rlike website, computer software, mobile app, API etc.\nHow to Install R ?\rOne basically needs to download two things to get started with R coding\ri.e.¬†R \u0026amp; R Studio. Think R as a engine whereas R studio as the whole car\rwhich supports the engines execution.\nDownload R from CRAN (Comprehensive R Archive Network)\r\rFirst of all go to this website and\rdownload the needed file depending upon your operating system. After you\rdownloaded, install the file and you are all set for first part.\nCRAN R\n\rDownload R Studio\r\rNow after downloading the R, you are all set to download the R Studio\rfrom this. Install the R Studio\rby opening up the downloaded file. There is nothing wierd setting to be\rset while installing, go with the flow.\nIf everything goes alright you should be able to set the R environment\rfor you analytical journey.\nR studio\n\r\r","date":1584662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584662400,"objectID":"078150b8b2545a2eba095b4aa277da72","permalink":"https://sharmajee499.netlify.app/post/install_r/","publishdate":"2020-03-20T00:00:00Z","relpermalink":"/post/install_r/","section":"post","summary":"R is a beautiful and powerful programming language. People always\rdebate about the Python vs.¬†R. For me, both have advantages in their\rrespective fields. I have used Python and R for about equal amount of\rtime.","tags":["Blogs"],"title":"Getting Started with R","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://sharmajee499.netlify.app/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://sharmajee499.netlify.app/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"Data: March 16, 2021 10:30 pm - 11:00 pm\nLocation: College of Business, Nicholls State University\nClass: Management of Organizations and Behavioral Processes (MNGT-301)\nThe slides can be accessed via the link.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://sharmajee499.netlify.app/talk/data-analytics-the-art-of-converting-numbers-into-decisions/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/data-analytics-the-art-of-converting-numbers-into-decisions/","section":"event","summary":"Data: March 16, 2021 10:30 pm - 11:00 pm\nLocation: College of Business, Nicholls State University\nClass: Management of Organizations and Behavioral Processes (MNGT-301)\nThe slides can be accessed via the link.","tags":null,"title":"Data Analytics: The Art of Converting Numbers into Decisions","type":"event"},{"authors":null,"categories":null,"content":"\r\rYes, I do also have a exhaustive list of wishes. I know these are just\rfew that came into my mind while I was writing this. However, I will\rkeep adding üòâ\n\rVisit all states of the America üá∫üá∏\n\rCruise Ship\n\rVisit Rara Lake üá≥üáµ\n\rRoller Coaster\n\rRun 5K\n\rSix Pack ü§£\n\rVisit all 75 districts of Nepal\n\rRead Bhagavad Gita üïâÔ∏è, Bible ‚úùÔ∏è and Quran ‚ò™Ô∏è\n\rWatch Lion King\n\rDrink Blue Label\n\rBungee jump\n\rDonate Blood\n\rDonate Hair\n\rPresent Ted Talk\n\rVisit Caribbean\n\r\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2282fc7e33e6a09f385d40169319bc50","permalink":"https://sharmajee499.netlify.app/bucket_list/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/bucket_list/","section":"","summary":"Yes, I do also have a exhaustive list of wishes. I know these are just\rfew that came into my mind while I was writing this. However, I will\rkeep adding üòâ","tags":null,"title":"The Bucket List","type":"page"}]