# No-SMOTE model
y_pred_nosmote = lr_noSmote.predict(X_test)
print('Accuracy: ',lr_noSmote.score(X_test, y_test))
print('AUC Score: ', roc_auc_score(y_test, y_pred_nosmote))
print('Confusion Matrix: ', "\n",confusion_matrix(y_test, y_pred_nosmote, labels=lr_noSmote.classes_), '\n')
# SMOTE Model
y_pred_smote = lr_smote.predict(X_test)
print('Accuracy: ',lr_smote.score(X_test, y_test))
print('AUC Score: ',roc_auc_score(y_test, y_pred_smote))
print('Confusion Matrix: ', "\n", confusion_matrix(y_test, y_pred_smote, labels=lr_smote.classes_))
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
# No-SMOTE model
y_pred_nosmote = lr_noSmote.predict(X_test)
print('Accuracy: ',lr_noSmote.score(X_test, y_test))
print('AUC Score: ', roc_auc_score(y_test, y_pred_nosmote))
print('Confusion Matrix: ', "\n",confusion_matrix(y_test, y_pred_nosmote, labels=lr_noSmote.classes_), '\n')
# SMOTE Model
y_pred_smote = lr_smote.predict(X_test)
print('Accuracy: ',lr_smote.score(X_test, y_test))
print('AUC Score: ',roc_auc_score(y_test, y_pred_smote))
print('Confusion Matrix: ', "\n", confusion_matrix(y_test, y_pred_smote, labels=lr_smote.classes_))
sm = SMOTE(random_state=112233, sampling_strategy=0.3)
X_res, y_res = sm.fit_resample(X_train, y_train)
print(Counter(y_train))
print(Counter(y_res))
sm = SMOTE(random_state=112233, sampling_strategy=0.3)
X_res, y_res = sm.fit_resample(X_train, y_train)
print('Original Data: ', Counter(y_train))
print('Smoted Data: ', Counter(y_res))
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.7)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.8)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.3)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.4)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test), 'Accuracy')
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix), 'auc')
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test))
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix))
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_), '\n')
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test))
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix))
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_))
install.packages("blogdown")
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
reticulate::repl_python()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from imblearn.datasets import fetch_datasets
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTE
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
# Get the 'Ecoli' Data
df = fetch_datasets()["abalone"]
# Seperate the feature and target
X, y = df.data, df.target
# Count the target-class
print(Counter(y))
# Get the 'Abalone' Data
df = fetch_datasets()["abalone"]
# Seperate the feature and target
X, y = df.data, df.target
# Count the target-class
print(Counter(y))
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=112233)
train_counter = Counter(y_train)
train_prop = [(i, train_counter[i]/len(X_train) * 100) for i in train_counter]
print(f"The train data prop: {train_prop}")
test_counter = Counter(y_test)
test_prop = [(i, test_counter[i]/len(X_test) * 100) for i in test_counter]
print(f"The test data prop: {test_prop}")
lr_noSmote = LogisticRegression(random_state=112233).fit(X_train, y_train)
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,
stratify=y, random_state=112233)
train_counter = Counter(y_train)
train_prop = [(i, train_counter[i]/len(X_train) * 100) for i in train_counter]
print(f"The train data prop: {train_prop}")
test_counter = Counter(y_test)
test_prop = [(i, test_counter[i]/len(X_test) * 100) for i in test_counter]
print(f"The test data prop: {test_prop}")
lr_noSmote = LogisticRegression(random_state=112233).fit(X_train, y_train)
sm = SMOTE(random_state=112233, sampling_strategy=0.3)
X_res, y_res = sm.fit_resample(X_train, y_train)
print('Original Data: ', Counter(y_train))
print('Smoted Data: ', Counter(y_res))
lr_smote = LogisticRegression(random_state=112233).fit(X_res, y_res)
# No-SMOTE model
y_pred_nosmote = lr_noSmote.predict(X_test)
print('Accuracy: ',lr_noSmote.score(X_test, y_test))
print('AUC Score: ', roc_auc_score(y_test, y_pred_nosmote))
print('Confusion Matrix: ', "\n",confusion_matrix(y_test, y_pred_nosmote,
labels=lr_noSmote.classes_), '\n')
# SMOTE Model
y_pred_smote = lr_smote.predict(X_test)
print('Accuracy: ',lr_smote.score(X_test, y_test))
print('AUC Score: ',roc_auc_score(y_test, y_pred_smote))
print('Confusion Matrix: ', "\n", confusion_matrix(y_test, y_pred_smote,
labels=lr_smote.classes_))
# No-SMOTE model
y_pred_nosmote = lr_noSmote.predict(X_test)
print('Accuracy (No Smote): ',lr_noSmote.score(X_test, y_test))
print('AUC Score (No Smote): ', roc_auc_score(y_test, y_pred_nosmote))
print('Confusion Matrix (No Smote): ', "\n",confusion_matrix(y_test, y_pred_nosmote,
labels=lr_noSmote.classes_), '\n')
# SMOTE Model
y_pred_smote = lr_smote.predict(X_test)
print('Accuracy (SMOTE): ',lr_smote.score(X_test, y_test))
print('AUC Score (SMOTE): ',roc_auc_score(y_test, y_pred_smote))
print('Confusion Matrix (SMOTE): ', "\n", confusion_matrix(y_test, y_pred_smote,
labels=lr_smote.classes_))
os = SMOTE(random_state=112233, sampling_strategy=0.3)
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
pipe = Pipeline(steps = [('over', os), ('u', us)])
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
print(Counter(y_mix))
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
y_pred_mix = lr_mix.predict(X_test)
print('Accuracy: ',lr_mix.score(X_test, y_test))
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix))
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_))
sm = SMOTE(random_state=112233, sampling_strategy=0.3)
X_res, y_res = sm.fit_resample(X_train, y_train)
print('Original Data: ', Counter(y_train))
print('Smoted Data: ', Counter(y_res))
# Over-Sample
os = SMOTE(random_state=112233, sampling_strategy=0.3)
# Under-Sample
us = RandomUnderSampler(random_state=112233, sampling_strategy=0.5)
# Pipeline
pipe = Pipeline(steps = [('over', os), ('u', us)])
# New train Dataset
X_mix, y_mix = pipe.fit_resample(X_train, y_train)
# Count of the new data
print(Counter(y_mix))
# Modeling
lr_mix = LogisticRegression(random_state=112233).fit(X_mix, y_mix)
# Prediction
y_pred_mix = lr_mix.predict(X_test)
# Metrices
print('Accuracy: ',lr_mix.score(X_test, y_test))
print('AUC Score: ',roc_auc_score(y_test, y_pred_mix))
print('Confusion Matrix: ',"\n",confusion_matrix(y_test, y_pred_mix, labels=lr_mix.classes_))
# No-SMOTE model
y_pred_nosmote = lr_noSmote.predict(X_test)
print('Accuracy (No Smote): ',lr_noSmote.score(X_test, y_test))
print('AUC Score (No Smote): ', roc_auc_score(y_test, y_pred_nosmote))
print('Confusion Matrix (No Smote): ', "\n",confusion_matrix(y_test, y_pred_nosmote,
labels=lr_noSmote.classes_), '\n')
# SMOTE Model
y_pred_smote = lr_smote.predict(X_test)
print('Accuracy (SMOTE): ',lr_smote.score(X_test, y_test))
print('AUC Score (SMOTE): ',roc_auc_score(y_test, y_pred_smote))
print('Confusion Matrix (SMOTE): ', "\n", confusion_matrix(y_test, y_pred_smote,
labels=lr_smote.classes_))
quit()
quit
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown::build_site()
reticulate::repl_python()
# Get the Data
pip install sklearn
pip install sklearn
# Get the Data
from sklearn.datasets import make_classification
from sklearn.datasets import make_classification
from collections import Counter
# Make the Synthetic Data
X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, weights=[0.80],flip_y=0.3, random_state = 112233)
# Data Statistics
print(f"Total number of instances in the dataset are {len(X)}")
print(f"The target class is unbalanced: {Counter(y)}")
from sklearn.model_selection import train_test_split
# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 112233, test_size=0.3, shuffle=True, stratify=y)
print(f"There are {len(X_train)} instances on the training and {len(X_test)} on testing set")
%%time
reticulate::repl_python()
# Train a Logistic regression model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
# Fit the model
lg = LogisticRegression().fit(X_train, y_train)
# Score on the training data
print(f"Training Data Accuracy: {lg.score(X_train, y_train)}")
print(f"Training Data F1: {f1_score(y_train, lg.predict(X_train))}")
# Predict the model
lg_pred = lg.predict(X_test)
# Evaluation on the testing set
print(f"Testing Data Accuracy: {lg.score(X_test, y_test)}")
print(f"Testing Data F1: {f1_score(y_test, lg_pred)}")
# Train a Logistic regression model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
# Fit the model
lg = LogisticRegression().fit(X_train, y_train)
# Score on the training data
print(f"Training Data Accuracy: {lg.score(X_train, y_train)}")
print(f"Training Data F1: {f1_score(y_train, lg.predict(X_train))}")
print("\n")
# Predict the model
lg_pred = lg.predict(X_test)
# Evaluation on the testing set
print(f"Testing Data Accuracy: {lg.score(X_test, y_test)}")
print(f"Testing Data F1: {f1_score(y_test, lg_pred)}")
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=112233)
#  Accuracy
scores_CV_acc = []
scores_test_acc = []
# F1 Score
scores_CV_f1 = []
scores_test_f1 = []
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(f"The accuracies of the 10 CV folds are: {scores_CV_acc}")
print(f"The accuracies of the 10 CV folds are: {scores_CV_acc}")
scores_CV_acc
View(scores_CV_acc)
[for i in scores_CV_acc]
[i for i in scores_CV_acc]
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=112233)
#  Accuracy
scores_CV_acc = list()
scores_test_acc = list()
# F1 Score
scores_CV_f1 = []
scores_test_f1 = []
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
scores_CV_acc
scores_CV_f1
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=112233)
#  Accuracy
scores_CV_acc = list()
scores_test_acc = list()
# F1 Score
scores_CV_f1 = []
scores_test_f1 = []
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(lg_cv.score(X_testCV, y_testCV))
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=112233)
#  Accuracy
scores_CV_acc = list()
scores_test_acc = list()
# F1 Score
scores_CV_f1 = []
scores_test_f1 = []
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(lg_cv.score(X_testCV, y_testCV))
for i in range(3):
print(i)
for i in range(3):
print(i)
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=112233)
#  Accuracy
scores_CV_acc = list()
scores_test_acc = list()
# F1 Score
scores_CV_f1 = []
scores_test_f1 = []
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(lg_cv.score(X_testCV, y_testCV))
for i in range(2):
print(i)
for i in range(2):
print(i)
for i in range(3):
print(i)
ls = []
for i in range(3):
ls.append(i)
ls
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(lg_cv.score(X_testCV, y_testCV))
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(lg_cv.score(X_testCV, y_testCV))
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(lg_cv.score(X_testCV, y_testCV))
for i in scores_CV_f1:
print(i)
for i in scores_test_f1:
print(i)
len(scores_test_f1)
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=112233)
#  Accuracy
scores_CV_acc = []
scores_test_acc = []
# F1 Score
scores_CV_f1 = []
scores_test_f1 = []
kf
kf.get_n_splits
kf.n_splits
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=112233)
#  Accuracy
scores_CV_acc = []
scores_test_acc = []
# F1 Score
scores_CV_f1 = []
scores_test_f1 = []
for train_index, test_index in kf.split(X_train, y_train):
X_trainCV, X_testCV = X_train[train_index], X[test_index]
y_trainCV, y_testCV = y_train[train_index], y[test_index]
lg_cv = LogisticRegression(random_state=112233).fit(X_trainCV, y_trainCV)
scores_CV_acc.append(lg_cv.score(X_testCV, y_testCV))
scores_test_acc.append(lg_cv.score(X_test, y_test))
scores_CV_f1.append(round(f1_score(y_testCV, lg_cv.predict(X_testCV)),2))
scores_test_f1.append(round(f1_score(y_test, lg_cv.predict(X_test)),2))
print(lg_cv.score(X_testCV, y_testCV))
for i in scores_test_f1:
print(i)
View(scores_CV_acc)
scores_CV_acc[0]
gc()
reticulate::repl_python()
import pandas as pd
import numpy as np
from statsmodels.tsa.arima_process import ArmaProcess #for data generation
from statsmodels.tsa.stattools import adfuller #adf test
# Assigning random coefficient
ar1 = np.array([1, -0.9])
# Since we are generating AR1 data the MA part remains constant
ma1 = np.array([1])
ar_obj = ArmaProcess(ar1, ma1)
np.random.seed(112233)
# Simulate the Data
simulate_ar1 = ar_obj.generate_sample(nsample=50)
# Convert the data to pandas data-frame
sim_ar1 = pd.DataFrame({'data': simulate_ar1})
sim_ar1.head()
adf_test_ar1 = adfuller(sim_ar1['data'])
adf_test_ar1 = adfuller(sim_ar1['data'])
print(f"The t-stat is: {adf_test_ar1[0]}")
adf_test_ar1 = adfuller(sim_ar1['data'])
print(f"The t-stat is: {adf_test_ar1[0]}")
print(f"The p-value is: {adf_test_ar1[1]}")
adf_test_ar1 = adfuller(sim_ar1['data'])
print(f"The t-stat is: {adf_test_ar1[0]}")
print(f"The p-value is: {adf_test_ar1[1]}")
exit
f
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
