---
title: "Math Behind Linear Regression: Gradient Descent"
author: "Sandesh"
date: "2022-02-23"
output: html_document
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>Gradient descent is one of the most popular optimization algorithms in the data science and machine learning.</p>
<p>For definition, as always, I investigated the Wikipedia. It says, “<em>In mathematics gradient descent (also often called steepest descent) is a <strong>first-order</strong> iterative optimization algorithm for <strong>finding a local minimum</strong> of a <strong>differentiate function</strong>. The idea is to take repeated steps in the <strong>opposite direction of the gradient</strong> (or approximate gradient) of the function at the current point, because this is the direction of steepest descent.</em>” Now, let me break down the key words from the definition to make ease.</p>
<p><u>Gradient:</u> Gradient is like a slope. It is the rate of change. The only difference is, slope term is used when there are two variables i.e., x and y, whereas the gradient is applicable in multi-dimensions. Moreover, slope is a scalar whereas gradient is vector</p>
<p><u>First-Order</u>: It only considers the first derivative when performing the update on the parameter.</p>
<p><u>Local Minimum</u>: The lowest point of the function. For instance, if the function looks like a parabola facing upward, lowest point is where your function outputs minimum value for a given x.</p>
<p><u>Differentiable Function</u>: It means we should be able to calculate the derivative of the given function. It sounds obvious. However, if you want to know what kind of function are differentiable, check out <a href="https://www.mathsisfun.com/calculus/differentiable.html">this</a> website.</p>
<p><u>Opposite Direction of Gradient:</u> Since our objective is to find the minimum point, we travel in the opposite direction of the gradient. If we have to reach to the maximum point, we would have travelled in the direction of the gradient.</p>
<p><u>Iterative:</u> It means finding minimum value by repeating the process until some criteria is met. The criteria can be number of iterations, change is gradient etc. depending upon the problem.</p>
<p>The above whole thing can be summarized by the picture in the top:</p>
<p>Woof, that’s a lot of definition and introduction. Now,let’s move over the application side. We will solve the problem of multiple regression using the Gradient Descent.</p>
<p>First, let’s start with the hypothesis. As we all know the general hypothesis of the linear regression in Ordinary Least Square Method is:</p>
<p><span class="math display">\[ h(x) = \beta_{0} + \beta_{1}x_{1} + \ldots+\beta_{n}x_{n} \tag{1}\]</span> However, we are going to change this equation with different machine learning notation, but the essence remains the same.</p>
<p><span class="math display">\[ h(x) = \theta_{0}x_{0}+\theta_{1}x_{1}+\ldots+\theta_{n}x_{n} \tag{2}\]</span> where <span class="math inline">\(x_{0} = 1\)</span> and <span class="math inline">\(x_{1},x_{2},\ldots,x_{n}\)</span> are the multiple input values.</p>
<p>This <span class="math inline">\(Equation2\)</span> can be changed into the matrix notation which will look like: <span class="math display">\[ h_{\theta}(x) = \theta^{T}x \tag{3}\]</span> <span class="math inline">\(x = [x_{0},x_{1},\ldots,x_{n}]\)</span> and <span class="math inline">\(\theta = [\theta_{0},\theta_{1},\ldots,\theta_{n}]\)</span></p>
<p>The whole purpose of the optimization algorithms is to find the optimal value. But what is the optimal situation for the Linear Regression Problem. It is finding the minimum error possible while modeling. In other words, finds the values of <span class="math inline">\(\theta\)</span> , such that it will give us the lowest error possible.</p>
<p>Now, from the statistics class you may have heard about the Mean Squared Error (MSE). As the word says itself, it is the average of the squared error/residuals. The formula for the MSE is</p>
<p><span class="math display">\[ MSE = \frac{1}{m}\sum_{i=1}^{m}\bigg[h_{\theta}(x^{(i)}) - y^{i} \bigg]^2 \tag{4}\]</span> In the Machine Learning lingo, we call this Loss Function which is modified further:</p>
<p><span class="math display">\[J(\theta_{0},\theta_{1},\ldots,\theta_{n}) = \frac{1}{2m}\sum_{i=1}^m \bigg[h_{\theta}(x^{(i)}) - y^{i} \bigg]^2 \tag{5}\]</span>
Now, let’s look at the update rule, meaning how should we change <span class="math inline">\(\theta\)</span> according to the gradient. As you can see, there is extra constant 2, which is introduced because it makes easier in taking derivatives.</p>
<p><span class="math display">\[ \theta_{j} := \theta_{j} - \alpha \frac{\partial}{\partial\theta_{j}}J(\theta) \tag{6}\]</span>
As we see, we introduced a new term <span class="math inline">\(\alpha\)</span> which is called learning rate. Learning rate is a hyper-parameter for the step size while climbing down the hill. Check <a href="https://developers.google.com/machine-learning/crash-course/reducing-loss/learning-rate">this</a> link for more info on learning rate.</p>
<p>For the understanding purpose, let’s first apply the update rule for <span class="math inline">\(\theta_{0}\)</span> only. The derivative is going to look like:</p>
<p><span class="math display">\[\text{Substituiting eq5 in eq6, we get}\]</span></p>
<p><span class="math display">\[\theta_{0} = \theta_{0} - \alpha \frac{\partial \bigg(\frac{1}{2m} \sum_{i=1}^{m} \big[h_{\theta}(x^{(i)}) - y^{(i)} \big] \bigg)^2}{\partial \theta_{0}} \]</span></p>
<p><span class="math display">\[\text{Using Chain Rule}\]</span></p>
<p><span class="math display">\[\theta_{0} = \theta_{0} - \alpha \bigg(\frac{2}{2m} \sum_{i=1}^{m} \big[h_{\theta}(x^{(i)}) - y^{(i)} \big] \bigg) \partial \frac {(h_{\theta}(x^{(i)}) - y^{(i)})} {\partial\theta_{0}} \]</span></p>
<p><span class="math display">\[\theta_{0} =\theta_{0} - \alpha \bigg(\frac{1}{m} \sum_{i=1}^{m} \big[h_{\theta}(x^{(i)}) - y^{(i)} \big] x_{0}^{(i)} \bigg) \tag{7}\]</span></p>
<p>Now, you must be wondering how we went to final step from second last step. Let me break it down for you:</p>
<p><span class="math display">\[ \partial \frac {(h_{\theta}(x^{(i)}) - y^{(i)})} {\partial\theta_{0}} \]</span></p>
<p><span class="math display">\[\text{From eq2, we can replace the } h_{\theta}(x^{(i)}) \text{ and we will take example for single row only}\]</span></p>
<p><span class="math display">\[\frac{\partial \big (\theta_{0}x_{0} + \ldots + \theta_{n}x_{n} - y     \big)}{\partial \theta_{0}}\]</span></p>
<p><span class="math display">\[=&gt; x_{0} \]</span></p>
<p>All part that doesn’t contain <span class="math inline">\(\theta_{0}\)</span> are constant so, derivative with respect to <span class="math inline">\(\theta_{0}\)</span> will give zero output.</p>
<p>This is just for the single observation, however for all observation it takes the form of the <span class="math inline">\(eq7\)</span>.</p>
<p><u><strong>Multiple Linear Regression Using Gradient Descent</strong></u></p>
<p>The same concept applies to the Multiple Linear Regression. Instead of doing it for only <span class="math inline">\(\theta_{0}\)</span>, we will do it for several variables.</p>
<p>The Gradient descent formula or update rule looks like:</p>
<p><span class="math display">\[ \text{repeat until convergence :}\]</span></p>
<p><span class="math display">\[\theta_{0} = \theta_{0} - \alpha \bigg(\frac{1}{m} \sum_{i=1}^{m}\big[h_{\theta}(x^{(i)}) - y^{(i)} \big]x_{0}^{(i)} \bigg) \]</span></p>
<p><span class="math display">\[\theta_{1} = \theta_{1} - \alpha \bigg(\frac{1}{m} \sum_{i=1}^{m}\big[h_{\theta}(x^{(i)}) - y^{(i)} \big]x_{1}^{(i)} \bigg) \]</span></p>
<p><span class="math display">\[\vdots \]</span></p>
<p><span class="math display">\[\theta_{n} =\theta_{n} - \alpha \bigg(\frac{1}{m} \sum_{i=1}^{m} \big[h_{\theta}(x^{(i)}) - y^{(i)} \big]x_{n}^{(i)} \bigg)\]</span></p>
<p>Here, <span class="math inline">\(\text{repeat untill convergence}\)</span> means updating the <span class="math inline">\(\theta\)</span>’s until some iteration (epochs) or criteria are reached.</p>
<p>This is just the tip of the Gradient Descent as it has wide application to offer. There are different types of Gradient Descent like Stochastic, Mini-batch which are more popular than the Batch Gradient Descent (Vanilla).</p>
<p>Understanding of Gradient Descent is must in the field of data science/machine learning. I hope this article was helpful to build some intuition behind the working principle. I am not using any code because there are different popular library that does those jobs.</p>
<p>If you want to understand the working of Gradient Descent in Excel, please check out this <a href="https://www.youtube.com/watch?v=3hYMuQXCj8c">link</a></p>
<div id="references" class="section level2">
<h2>References</h2>
<p>Image Link: <a href="https://towardsdatascience.com/stochastic-gradient-descent-explained-in-real-life-predicting-your-pizzas-cooking-time-b7639d5e6a32" class="uri">https://towardsdatascience.com/stochastic-gradient-descent-explained-in-real-life-predicting-your-pizzas-cooking-time-b7639d5e6a32</a></p>
<p>Wikimedia Foundation. (2022, February 15). <em>Gradient descent.</em> Wikipedia. Retrieved February 24, 2022, from <a href="https://en.wikipedia.org/wiki/Gradient_descent" class="uri">https://en.wikipedia.org/wiki/Gradient_descent</a></p>
<p>Géron, A. (2020). <em>Hands-on machine learning with scikit-learn, Keras, and tensorflow: Concepts, tools, and techniques to build Intelligent Systems.</em> O’Reilly.</p>
<p>Mani, A. (2019, December 1). <em>Solving multivariate linear regression using gradient descent.</em> Atma’s blog. Retrieved February 24, 2022, from <a href="https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/" class="uri">https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/</a></p>
<p>Gunjal, S. (2020, May 13). <em>Multivariate linear regression from scratch with python.</em> Quality Tech Tutorials. Retrieved February 24, 2022, from <a href="https://satishgunjal.com/multivariate_lr/" class="uri">https://satishgunjal.com/multivariate_lr/</a></p>
</div>
