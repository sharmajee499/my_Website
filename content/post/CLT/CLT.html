---
title: "Central Limit Theorem"
author: "Sandesh"
date: "2022-12-25"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
image:
  placement: 2
  caption: "Photo by [Naser Tamimi](https://unsplash.com/photos/yG9pCqSOrAg)"
---



<div id="introduction" class="section level4">
<h4>Introduction</h4>
<p>We all heard about the Central Limit Theorem (CTL) in out basis statistics class. It is one of the fundamental theorem in statistics and is applied in numerous analytics and statistics analysis. Without any delay, let me state what the theorem says:</p>
<blockquote>
<p>Let <span class="math inline">\(X_1, X_2,...., X_n\)</span> be a random sample from a distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Then if <span class="math inline">\(n\)</span> is sufficiently large, <span class="math inline">\(\bar{X}\)</span> has approximately a normal distribution with <span class="math inline">\(\mu_{\bar{X}} = \mu\)</span> and <span class="math inline">\(\sigma{^2}_{\bar{X}} = \frac{\sigma^2}{n}\)</span>. The larger the value of <span class="math inline">\(n\)</span>, the better the approximation. The larger the value of <span class="math inline">\(n\)</span>, the better the approximation. Devore, J. L. (2000)</p>
</blockquote>
<p>Woof, that’s a mathematical definition. Now, let’s break it down in simple words. All that this is saying is that, if we have distribution (any distribution) and draw <span class="math inline">\(n\)</span> samples for <span class="math inline">\(m\)</span> times and plot it’s histogram then, that will resemble to the normal distribution. As a rule of thumb, &gt;30 is a ideal value for the <span class="math inline">\(n\)</span>. The below, picture will give you more sense.</p>
<div class="figure">
<img src="CLT_Picture.png" alt="" />
<p class="caption">CLT_Figure</p>
</div>
</div>
<div id="the-math-problem" class="section level4">
<h4>The Math Problem</h4>
<p>Let’s take a math problem that you may have solved in some statistics class but never realized you utilized the CLT theorem. I am copying this problem from Devore, J. L. (2000).</p>
<blockquote>
<p>The amount of a particular impurity in a batch of a certain chemical product is a random variable with mean value 4.0 g and standard deviation 1.5 g. If 50 batches are independently prepared, what is the (approximate) probability that the sample average amount of <span class="math inline">\(\bar{X}\)</span> impurity is between 3.5 and 3.8 g?</p>
</blockquote>
<p>The first thing you should note is that, we don’t know which distribution the samples came from. What we know is that, we have 50 batched whose mean is 4 and standard deviation is 1.5. As stated above, 30 is the ideal to use CLT however, here we got 50 so, we should be good to use CLT. One more thing to note is that, the standard deviation is for the means not for the sample. So, we have to calculate the standard error of the mean <span class="math inline">\((\sigma_{\bar{X}})\)</span> which can be calculated as: <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span></p>
<p>So, to find the probability we can use the properties of normal distribution as the samples satisfies the CLT theorem with the <span class="math inline">\(\mu_{\bar{X}}=4\)</span> and <span class="math inline">\((\sigma_{\bar{X}}) = \frac{1.5}{\sqrt{50}} = 0.2121\)</span> so,</p>
<p><span class="math display">\[P(3.5 \leq 3.8) = P \left(\frac{3.5-4.0}{.2121} \leq Z \leq \frac{3.8-4.0}{.2121}\right)\]</span> <span class="math display">\[ = 0.1645\]</span></p>
<p>I skipped some steps here. We have the get the respective probability for the Z score and subtract. Since, the main agenda was to understand the problem and realize how CLT is used to solve, I skipped that part. I hope, this gives you more sense. At the start of the problem, we didn’t have idea about the distribution but we solved the problem using CLT. And, that’s the power and beauty of CLT.</p>
</div>
<div id="the-application" class="section level3">
<h3>The Application</h3>
<p>You understood the theorem also solved a math problem and realized it wasn’t that hard. Now let’s take a real life application to better understand the CLT.</p>
<div id="the-mushroom-farm-problem" class="section level4">
<h4>The Mushroom Farm Problem</h4>
<p>Let’s suppose you are a farmer and you have a big mushroom farm. To give more context, let assume you have 4 farming plots where you have planted about 10,000 mushroom. For simplicity, let’s also assume that all the 4 plots nature is somewhat identical. Meaning, the mushroom are planted on same time, there are same numbers of mushroom planted, they are of same type and they are also exposed to same fertilizers and environment.</p>
<p>Now you are an agriculturist who have an intense background in statistics so wanted to know the probability that the mushrooms on your farms are between some range that will give you maximum profit. If you harvest it early or late, you wouldn’t be able to The simple way to solve this problem is to measure every mushroom on those 4 field, get the data and draw a probability distribution to get the answer. The mushroom farm is visualized below:</p>
<div class="figure">
<img src="mushroom_farm.png" alt="" />
<p class="caption">mushroom_farm</p>
</div>
<p>However, that solutions have a lot of problems. It is very time consuming and expensive and definitely not feasible. On other hand, the statistical problem is that we don’t know the distribution of the mushroom size so we can’t do any statistics and probability analysis.</p>
<p>Therefore, in such scenario our CLT comes handy.</p>
</div>
<div id="solution" class="section level4">
<h4>Solution</h4>
<p>So, to find out the probability that our mushrooms are in certain range we can use the CLT. We are going to draw <span class="math inline">\(n\)</span> samples from the Farm 1. Since, we assumed our Farms are same. We also going to take <span class="math inline">\(m\)</span> numbers of samples from the farm. At the end, we will get the <span class="math inline">\(m\)</span> number of means from the Farm 1 sampling.</p>
<p>We will walk through the Python code to understand it workings.</p>
<pre class="python"><code>
# Import the Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt</code></pre>
<p>Initially, we said we don’t need to know what distribution the samples comes from and that is still true. However, for the code perspective, I am going to simulate the data points from the exponential distribution. In the function <code>rng.exponential</code>, the first parameter is <span class="math inline">\(\beta = \frac{1}{\lambda}\)</span>. Therefore, our $ $. The mean of the exponential distribution is <span class="math inline">\(\lambda\)</span> therefore, the mean of the simulated data points are 1.</p>
<pre class="python"><code>
# Exponential Distribution or Farm 1 data-points
rng = np.random.default_rng(seed=112233)
exp_dist = rng.exponential(1, 10000)

sns.histplot(exp_dist, kde=True)
plt.title(&quot;Simulated Exponential Distribution&quot;)</code></pre>
<p><img src="/post/CLT/CLT_files/figure-html/Simulated%20Data-1.png" width="672" /></p>
<div class="figure">
<img src="simulated_exp_dist.png" alt="" />
<p class="caption">simulated_data_dist</p>
</div>
<p>The below <code>sample_mean</code> function calculates the mean of the samples <code>sample_size</code>, up-to <code>n_samples</code> times. So, at the end the function will return the list of the means.</p>
<pre class="python"><code>
# Sample Mean Calculator function
def sample_mean(distribution_array, sample_size, n_samples):

    # Initialized the list to store value
    sample_mean = []

    for i in range(n_samples):

        # Choose the random samples (Sampling)
        sample = np.random.choice(distribution_array, sample_size,)

        # Calculate the mean of the drawn sample
        mean = np.mean(sample)

        # Append the result
        sample_mean.append(mean)

    return sample_mean</code></pre>
<p>Now, we will draw the graphs of the sample mean distribution for different samples that were drawn from the exponential distribution.</p>
<pre class="python"><code>
# Plots for different sample sizes
fig, axs = plt.subplots(2,2)
sns.histplot(ax=axs[0,0], x=sample_mean(exp_dist, 1, 500), kde=True)
axs[0,0].set_title(&quot;Sample Drawn: 1, 500 Times&quot;)
sns.histplot(ax=axs[0,1], x=sample_mean(exp_dist, 10, 500), kde=True)
axs[0,1].set_title(&quot;Sample Drawn: 10, 500 Times&quot;)
sns.histplot(ax=axs[1,0], x=sample_mean(exp_dist, 30, 500), kde=True)
axs[1,0].set_title(&quot;Sample Drawn: 30, 500 Times&quot;)
sns.histplot(ax=axs[1,1], x=sample_mean(exp_dist, 50, 500), kde=True)
axs[1,1].set_title(&quot;Sample Drawn: 50, 500 Times&quot;)
fig.tight_layout()
plt.show()</code></pre>
<p><img src="/post/CLT/CLT_files/figure-html/unnamed-chunk-1-3.png" width="672" /></p>
<p>From the above figure, you can clearly see that as we increased the sample size, the distribution is getting closer and closer to normal. With such approximation, we can use the properties of the normal distribution to calculate the various statistics. For example, if we collect large samples like more then 30, we can even do t-test among the different farms even though we don’t have any clue what distribution they follow.</p>
<p>At conclusion, I hope now you have a better understanding of CLT and how it can be used in practice life. I would highly recommend to watch <a href="https://www.youtube.com/watch?v=N7wW1dlmMaE">this</a> video if you want to understand from a different application perspective.</p>
</div>
</div>
<div id="references" class="section level3">
<h3>References</h3>
<p>Devore, J. L. (2000). Probability and statistics for engineering and the sciences (5th ed.). Duxbury.</p>
<p>365 Data Science. (2020, December 21). Real-world application of the Central Limit Theorem (CLT) [Video]. YouTube. <a href="https://www.youtube.com/watch?v=N7wW1dlmMaE" class="uri">https://www.youtube.com/watch?v=N7wW1dlmMaE</a></p>
</div>
